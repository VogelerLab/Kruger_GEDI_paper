{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad44e655-d5a6-4805-9d7a-5707405bf7df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kruger Veg mapping data prep  \n",
    "Prepare remote sensing and other data sources for modeling and mapping of LCLUC in the Kruger area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99facc8-ad9c-47da-85c7-1ca44e1b264b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, itertools, sys, time, subprocess\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shapely, ee, rasterio\n",
    "\n",
    "sys.path.append(r'J:\\users\\stevenf\\code\\language\\python')\n",
    "from sfgeo.raster_bounds import aoi_raster\n",
    "\n",
    "# load earth engine functions\n",
    "sys.path.append(r'J:\\users\\stevenf\\code\\utils\\pee')\n",
    "# from landsat import *\n",
    "# from time_series import *\n",
    "import landsat as lxtools\n",
    "import time_series\n",
    "import sar\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db929f7c-1425-4af2-8d73-0a9716d8b353",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Functions used multiple times for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b211e1-ebf9-48c0-8c58-85bf2bdb4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run list of commands with concurrent threads\n",
    "# TODO: look for better library to do this (joblib?) or make better non-blocking, reusable function with progress bar.\n",
    "def cmd_concurrent(cmds, threads=1): \n",
    "    from subprocess import Popen\n",
    "    from itertools import islice\n",
    "    \n",
    "    processes = (Popen(cmd, shell=True) for cmd in cmds)\n",
    "    running_processes = list(islice(processes, threads))  # start new processes\n",
    "    while running_processes:\n",
    "        for i, process in enumerate(running_processes):\n",
    "            if process.poll() is not None:  # the process has finished\n",
    "                running_processes[i] = next(processes, None)  # start new process\n",
    "                if running_processes[i] is None: # no new processes\n",
    "                    del running_processes[i]\n",
    "                    break\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4edc3-6478-48cc-9524-6ecbba6f5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyramid and stats helper function\n",
    "# If pyramids are generated for the tiles before creating VRT mosaics then gdalbuildvrt will recognize the \n",
    "# presence of the pyramids and add a line in the XML file to use them. They can then be used for doing \n",
    "# approximate statistics too.\n",
    "def pyr_stats(path, nodata=None, run=True):\n",
    "    \"\"\"Set nodata (str of number or 'nan'). Calculate stats and pyramids for image at path (str).\"\"\"\n",
    "    cmds = {'stats':[], 'pyr':[]}\n",
    "    if nodata:\n",
    "        cmd = 'rio edit-info --nodata ' + str(nodata) + ' ' + path\n",
    "        result = subprocess.check_output(cmd)\n",
    "    \n",
    "    stats_cmd = 'gdalinfo -approx_stats --config GDAL_PAM_ENABLED TRUE ' + path\n",
    "    if run:\n",
    "        result = subprocess.check_output(stats_cmd)\n",
    "    \n",
    "    if not os.path.exists(path[:-4]+\".ovr\"):\n",
    "        pyr_cmd = 'gdaladdo -ro --config COMPRESS_OVERVIEW ZSTD --config ZSTD_LEVEL 1 --config PREDICTOR 2 --config INTERLEAVE_OVERVIEW BAND --config GDAL_CACHEMAX 4096 ' + path\n",
    "        if run:\n",
    "            result = subprocess.check_output(pyr_cmd)\n",
    "    \n",
    "    return stats_cmd, pyr_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e239c97-f00a-4567-ab37-8fd4374a446b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AOI  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fed0b-0116-4611-8512-e578f2ef9128",
   "metadata": {},
   "source": [
    "## GKSDP\n",
    "Greater Kruger Sustainable Development Program boundary. Mask and tiles made in UTM36N aligned to Landsat products. This was used in LandTrendr analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb977af-b1da-4fcf-80f1-88a3d4113c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Greater Kruger AOI to UTM 36 North since Landsat always uses North,\n",
    "# even in the southern hemisphere\n",
    "path = r\"J:\\projects\\ECOFOR\\ancillary_data\\GKSDP_Area_Prj\\GKSDP_Area_Prj.shp\"\n",
    "outpath = r\"J:\\projects\\ECOFOR\\ancillary_data\\greaterkruger_utm36n.gpkg\"\n",
    "df = gpd.read_file(path).to_crs(epsg=32636)\n",
    "df.to_file(outpath, driver=\"GPKG\")\n",
    "\n",
    "# Also save as shp file for upload to GEE.\n",
    "shp_path = os.path.splitext(outpath)[0]+\".shp\"\n",
    "df.to_file(shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba87d8-58be-4631-8e0b-57df6b6d1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tile scheme for UTM 36N that aligns the landsat pixels.\n",
    "tile_dimx = 5000 * 30\n",
    "tile_dimy = 5000 * 30\n",
    "offset = 15             # to match landsat\n",
    "outpath = r\"J:\\projects\\ECOFOR\\ancillary_data\\tiles_utm36n.gpkg\"\n",
    "\n",
    "# Use arbitrary starting point for y that is around where utm36N intersects south africa\n",
    "basey = -3700000 #36N   #6300000 #35S\n",
    "\n",
    "startx = 0 + offset\n",
    "starty = (basey // tile_dimy) * tile_dimy + 15\n",
    "h, v = np.meshgrid(np.arange(10), np.arange(6))\n",
    "\n",
    "df = pd.DataFrame({'h':v.ravel(), 'v':h.ravel()})\n",
    "df['minx'] = df['h'] * tile_dimx + startx\n",
    "df['maxx'] = df['minx'] + tile_dimx\n",
    "df['miny'] = df['v'] * tile_dimy + starty\n",
    "df['maxy'] = df['miny'] + tile_dimy\n",
    "df['geometry'] = df.apply(lambda r: shapely.geometry.box(r.minx, r.miny, r.maxx, r.maxy), axis=1)\n",
    "df['hv'] = df.apply(lambda r: \"{:02d}\".format(r.h) + \"{:02d}\".format(r.v), axis=1)\n",
    "\n",
    "df = gpd.GeoDataFrame(df, geometry='geometry', crs=aoi.crs)\n",
    "df.to_file(outpath, driver='GPKG')\n",
    "# df.to_file(os.path.splitext(outpath)[0]+\".shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c1f060-ef05-4e86-b16e-7fb09dba113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save aoi as mask that aligns with Landsat data\n",
    "template_path = r\"D:\\ecofor\\lt\\dry\\lt_dry_1984.vrt\" # any lt raster to get pixel alignment\n",
    "df_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.gpkg\"\n",
    "df = gpd.read_file(df_path)\n",
    "outpath = df_path[:-5]+\".tif\"\n",
    "\n",
    "df = df.to_crs(epsg=32636)\n",
    "\n",
    "bounds, dims = aoi_raster(df.unary_union, template_path)\n",
    "cmd = (\"gdal_rasterize -burn 1 -tr 30 30 -te \" + \n",
    "       \" \".join([str(b) for b in bounds]) + \n",
    "       \" -ot Byte -co COMPRESS=LZW\" + \n",
    "       \" -co TILED=YES\" +\n",
    "       \" \" + df_path + \" \" + outpath)\n",
    "print(cmd)\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92159842-bb0f-45e8-9ac9-3e75bdd286a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for KNP\n",
    "path = r\"J:\\projects\\ECOFOR\\boundaries\\Kruger.shp\"\n",
    "outpath = r\"J:\\projects\\ECOFOR\\boundaries\\kruger_utm36n.gpkg\"\n",
    "df = gpd.read_file(path).to_crs(epsg=32636)\n",
    "df.to_file(outpath, driver=\"GPKG\")\n",
    "\n",
    "# save aoi as mask that aligns with Landsat data\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\" # created this in the veg.ipynb\n",
    "df_path = outpath\n",
    "df = gpd.read_file(df_path)\n",
    "outpath = df_path[:-5]+\".tif\"\n",
    "\n",
    "bounds, dims = aoi_raster(df.unary_union, template_path)\n",
    "cmd = (\"gdal_rasterize -burn 1 -tr 30 30 -te \" + \n",
    "       \" \".join([str(b) for b in bounds]) + \n",
    "       \" -ot Byte -co COMPRESS=LZW\" + \n",
    "       \" -co TILED=YES\" +\n",
    "       \" \" + df_path + \" \" + outpath)\n",
    "print(cmd)\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a9e39-309a-4020-a659-b3f682434b91",
   "metadata": {},
   "source": [
    "### MGRS UTM 36\n",
    "Make an AOI and mask based on the intersection of GKSDP area with the UTM 36 MGRS tiles used for generating CCDC. MGRS tiles created under GKNP below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d033d5-2851-49ea-a387-e0231b1b47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect GKSDP and MGRS tile area\n",
    "tiles_path = r\"J:\\projects\\ECOFOR\\boundaries\\mgrs_utm36n.gpkg\"\n",
    "aoi_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.gpkg\"\n",
    "outpath = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n_mgrsclip.gpkg\"\n",
    "\n",
    "tiles = gpd.read_file(tiles_path)\n",
    "tiles = tiles.unary_union\n",
    "aoi = gpd.read_file(aoi_path)\n",
    "\n",
    "df = gpd.GeoDataFrame(geometry=aoi.intersection(tiles))\n",
    "df['area_km2'] = df['geometry'].area / 1000**2\n",
    "\n",
    "df.to_file(outpath, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e38da1-4a4c-416b-adf6-1e4b747580de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save aoi as mask that aligns with Landsat data\n",
    "template_path = r\"J:\\projects\\ECOFOR\\lt\\dry\\lt_dry_1984.vrt\" # any lt raster to get pixel alignment\n",
    "df_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n_mgrsclip.gpkg\"\n",
    "df = gpd.read_file(df_path)\n",
    "outpath = df_path[:-5]+\".tif\"\n",
    "\n",
    "df = df.to_crs(epsg=32636)\n",
    "\n",
    "bounds, dims = aoi_raster(df.unary_union, template_path)\n",
    "cmd = (\"gdal_rasterize -burn 1 -tr 30 30 -te \" + \n",
    "       \" \".join([str(b) for b in bounds]) + \n",
    "       \" -ot Byte -co COMPRESS=LZW\" + \n",
    "       \" -co TILED=YES\" +\n",
    "       \" \" + df_path + \" \" + outpath)\n",
    "print(cmd)\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419433ca-9bea-4add-8f25-d92fca9e3654",
   "metadata": {},
   "source": [
    "## GKNP  \n",
    "Custom area that includes Kruger National Park, associated private nature reserves (APNR), and communal lands in savanna. Excludes much of the forest plantations and agriculture land that is of less interest.  \n",
    "\n",
    "A mask and tiles are created in the MGRS system used by Sentinel-2 and HLS except only the UTM zone 36N tiles are used and overlap is removed. This should allow a tile to be processed without duplicate pixels because processing a tile can filter only for that tile name (excluding the overlapping tile). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404badb-3bed-479b-9651-a157b19e706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge KNP boundary (from data_prep.ipynb) and connected APNR boundaries\n",
    "from shapely.geometry import Multipolygon, Polygon\n",
    "outpath = r\"J:\\projects\\ECOFOR\\boundaries\\kruger_apnr_utm36n.gpkg\"\n",
    "\n",
    "path = r\"J:\\projects\\ECOFOR\\boundaries\\kruger_utm36n.gpkg\"\n",
    "df1 = gpd.read_file(path)\n",
    "\n",
    "path = r\"J:\\projects\\ECOFOR\\boundaries\\SAPAD_OR_2021_Q3_KNPconnected.shp\"\n",
    "df2 = gpd.read_file(path)\n",
    "df2 = df2.to_crs(df1.crs)\n",
    "apnr = df2.unary_union.buffer(0)\n",
    "\n",
    "merged_geo = df1.union(apnr).buffer(0).iloc[0]\n",
    "no_holes = MultiPolygon(Polygon(p.exterior) for p in merged_geo.geoms)\n",
    "merged = gpd.GeoDataFrame(geometry=[no_holes], crs=df1.crs)\n",
    "merged['area_km2'] = merged.area / (1000**2)\n",
    "\n",
    "merged.to_file(outpath, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b8fc0-3860-4e71-8206-9f6b7ab446c6",
   "metadata": {},
   "source": [
    "**The kruger_apnr_utm36n boundary created above was manually edited to fill small gaps. This is renamed below as 'gknp', which may be edited later to add communal lands.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193108d-9c07-40d0-865e-9b885147368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"J:\\projects\\ECOFOR\\boundaries\\kruger_apnr_utm36n_filled_v2.gpkg\"\n",
    "outpath = r\"J:\\projects\\ECOFOR\\boundaries\\gknp_utm36n_v2.gpkg\"\n",
    "df = gpd.read_file(path)\n",
    "\n",
    "df = df.buffer(0)\n",
    "df.to_file(outpath, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a3a9f-5a2e-4203-9b99-ff5d60a04b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MGRS tiles overlapping gknp\n",
    "outpath = r\"J:\\projects\\ECOFOR\\boundaries\\mgrs_utm36n.gpkg\"\n",
    "path = r\"J:\\projects\\ECOFOR\\boundaries\\S2A_OPER_GIP_TILPAR_MPC__20151209T095117_V20150622T000000_21000101T000000_B00.kml\"\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['LIBKML'] = 'rw'\n",
    "mgrs = gpd.read_file(path)\n",
    "mgrs = mgrs.to_crs(epsg=32636)\n",
    "\n",
    "# # Filter to 36N tiles intersecting aoi\n",
    "# mgrs = mgrs[mgrs['Name'].str.startswith('36')]\n",
    "# mgrs = mgrs.to_crs(df.crs)\n",
    "# mgrs = mgrs[mgrs.intersects(df.unary_union)]\n",
    "\n",
    "# Filter to a list of intersecting 36N tiles while excluding unnecessary overlaps\n",
    "mgrs['name'] = mgrs['Name']\n",
    "tiles = {'36KTA': {'h':0,'v':4},\n",
    "         '36KUA': {'h':1,'v':4},\n",
    "         '36KTV': {'h':0,'v':3},\n",
    "         '36KUV': {'h':1,'v':3},\n",
    "         '36KTU': {'h':0,'v':2},\n",
    "         '36KUU': {'h':1,'v':2},\n",
    "         '36JTT': {'h':0,'v':1},\n",
    "         '36JUT': {'h':1,'v':1},\n",
    "         '36JTS': {'h':0,'v':0},\n",
    "         '36JUS': {'h':1,'v':0}}\n",
    "mgrs = mgrs[mgrs['name'].isin(tiles.keys())]\n",
    "mgrs['h'] = mgrs['name'].apply(lambda n: tiles[n]['h'])\n",
    "mgrs['v'] = mgrs['name'].apply(lambda n: tiles[n]['v'])\n",
    "mgrs['hv'] = mgrs.apply(lambda r: \"{:02d}\".format(r.h) + \"{:02d}\".format(r.v), axis=1)\n",
    "\n",
    "# Round coordinates to fix projection imprecision and get tile boundaries\n",
    "mgrs['geometry'] = mgrs['geometry'].apply(lambda x: shapely.wkt.loads(shapely.wkt.dumps(x, rounding_precision=0)).buffer(0))\n",
    "mgrs = pd.concat([mgrs, mgrs['geometry'].bounds], axis=1)\n",
    "\n",
    "# New tiling without overlap\n",
    "mgrs['minx'] = mgrs['minx']+4890.0\n",
    "mgrs['maxx'] = mgrs['maxx']-4890.0\n",
    "mgrs['miny'] = mgrs['miny']+4890.0 \n",
    "mgrs['maxy'] = mgrs['maxy']-4890.0 \n",
    "\n",
    "# top and bottom tiles need to be shifted out for some reason\n",
    "mgrs.loc[mgrs['v']==4, ['miny', 'maxy']]+=60\n",
    "mgrs.loc[mgrs['v']==0, ['miny', 'maxy']]-=60\n",
    "\n",
    "mgrs['geometry'] = mgrs.apply(lambda r: shapely.geometry.box(r['minx'], r['miny'], r['maxx'], r['maxy']), axis=1)\n",
    "\n",
    "cols = ['name', 'hv', 'h', 'v', 'minx', 'miny', 'maxx', 'maxy', 'geometry']\n",
    "mgrs[cols].to_file(outpath, driver=\"GPKG\")\n",
    "mgrs[cols].to_file(outpath[:-5]+\".shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfdaf84-c125-41fc-9532-58816ccfd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save aoi as mask that aligns with Landsat data\n",
    "template_path = r\"H:\\ecofor\\lt\\dry\\lt_dry_1984.vrt\" # any lt raster to get pixel alignment\n",
    "df_path = r\"J:\\projects\\ECOFOR\\boundaries\\gknp_utm36n_v2.gpkg\" # r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.gpkg\"\n",
    "df = gpd.read_file(df_path)\n",
    "outpath = df_path[:-5]+\".tif\"\n",
    "\n",
    "df = df.to_crs(epsg=32636)\n",
    "\n",
    "bounds, dims = aoi_raster(df.unary_union, template_path)\n",
    "cmd = (\"gdal_rasterize -burn 1 -tr 30 30 -te \" + \n",
    "       \" \".join([str(b) for b in bounds]) + \n",
    "       \" -ot Byte -co COMPRESS=LZW\" + \n",
    "       \" -co TILED=YES\" +\n",
    "       \" \" + df_path + \" \" + outpath)\n",
    "print(cmd)\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e3bb7-7728-4529-b6dc-6b2d9fbeae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create study area masks aligned to the MGRS tile scheme\n",
    "df_path = r\"J:\\projects\\ECOFOR\\boundaries\\gknp_utm36n_v2.gpkg\"\n",
    "tiles_path = r\"J:\\projects\\ECOFOR\\boundaries\\mgrs_utm36n.gpkg\"\n",
    "outpath = df_path[:-5]+\"_mgrs.tif\"\n",
    "\n",
    "df = gpd.read_file(df_path)\n",
    "tiles = gpd.read_file(tiles_path)\n",
    "\n",
    "bounds = (tiles['minx'].min(), tiles['miny'].min(), tiles['maxx'].max(), tiles['maxy'].max())\n",
    "cmd = (\"gdal_rasterize -burn 1 -tr 30 30 -te \" + \n",
    "       \" \".join([str(b) for b in bounds]) + \n",
    "       \" -ot Byte -co COMPRESS=LZW\" + \n",
    "       \" -co TILED=YES\" +\n",
    "       \" \" + df_path + \" \" + outpath)\n",
    "print(cmd)\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce326124-eb0f-4c94-ae64-f9ea8720530c",
   "metadata": {},
   "source": [
    "## GEDI download area\n",
    "Buffer and then simplify and then densify the AOI for GEDI download to ensure that no granules that may be on the edge of the study area are also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fe274-85b2-4516-bc20-c8a74a10e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original AOI\n",
    "path = r\"J:\\projects\\ECOFOR\\boundaries\\GKSDP_Area_Prj\\GKSDP_Area_Prj.shp\"\n",
    "outpath = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_buf1000simp_wgs84.gpkg\"\n",
    "\n",
    "aoi = gpd.read_file(path)\n",
    "\n",
    "# Buffer AOI\n",
    "poly = aoi.buffer(5000)[0]\n",
    "\n",
    "# Simplify to get rid of redundant vertices within tolerance\n",
    "poly = poly.simplify(50, preserve_topology=True)\n",
    "\n",
    "# Densify vertices with OGR segmentize; this will help to preserve points actually intersecting the study area after conversion to WGS84\n",
    "def segmentize(geom, max_dist):\n",
    "    wkt = geom.wkt  # shapely Polygon to wkt\n",
    "    geom = ogr.CreateGeometryFromWkt(wkt)  # create ogr geometry\n",
    "    geom.Segmentize(max_dist)  # densify geometry\n",
    "    wkt2 = geom.ExportToWkt()  # ogr geometry to wkt\n",
    "    new = shapely.wkt.loads(wkt2)  # wkt to shapely Polygon\n",
    "    return new\n",
    "\n",
    "poly_dense = segmentize(poly, 2000)\n",
    "\n",
    "aoi_out = gpd.GeoDataFrame([{'id':0,'geometry':poly_dense, 'area_km2':poly_dense.area/(1000*1000)}], crs=aoi.crs)\n",
    "\n",
    "# transform and export\n",
    "aoi_out = aoi_out.to_crs(epsg=4326)\n",
    "aoi_out.to_file(outpath, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcf57a-9a1e-46a8-b85c-ed0344253fa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LandTrendr\n",
    "Export dry and wet season landtrendr time series, reorganize, and mosaic.\n",
    "\n",
    "Wet season dates go to the following year so 2022 dry is May 1, 2022 to Sept 30, 2022, and 2022 wet is Oct 1, 2022 to Apr 30, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b40825-5c92-4eae-b15f-fa1ee8e2167b",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605c84f-ed00-4146-810e-0cfb8760d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stat images for TDOM (cloud shadow masking)\n",
    "# # These TDOM images are only for the US so the mean and std images will need to be calculated for Kruger\n",
    "# TDOMStats = ee.ImageCollection('projects/lcms-tcc-shared/assets/CS-TDOM-Stats/TDOM').mosaic().divide(10000) #divide if using 0-1 imagery, don't if using unscaled images (0-10,000)\n",
    "# mean_img = TDOMStats.select(['Landsat_nir_mean', 'Landsat_swir1_mean'], ['nir', 'swir1'])\n",
    "# stddev_img = TDOMStats.select(['Landsat_nir_stdDev', 'Landsat_swir1_stdDev'], ['nir', 'swir1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c73bba-c7e5-49b2-a3ea-40a7658d97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "starty = 1984\n",
    "endy = 2022\n",
    "season = 'wet' #'dry'\n",
    "if season=='dry':\n",
    "        startdoy, enddoy = 121, 273 # May 1st, Sept 30 - non-leap year\n",
    "elif season=='wet':\n",
    "        startdoy, enddoy = 274, 120 # Oct 1st, Apr 30 - non-leap year\n",
    "fill = True  \n",
    "date_band = False  # TODO: fix code below to allow export of a date band\n",
    "orig_bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']\n",
    "ixbands = ['ndvi', 'nbr', 'ndmi','tcb', 'tcg', 'tcw']\n",
    "coll_kwargs = {'bands':orig_bands, 'rescale':True, 'cloud_cover':50, 'tdom':False}\n",
    "              # 'tdom':True, 'tdom_kwargs':{'mean_img':mean_img, 'stddev_img':stddev_img, 'sum_thresh':.35}} # need to compute TDOM stats for Kruger on the fly)\n",
    "comp_kwargs = {'date_band':date_band}\n",
    "lt_kwargs = { \n",
    "  'maxSegments':            6,\n",
    "  'spikeThreshold':         0.9,\n",
    "  'vertexCountOvershoot':   3,\n",
    "  'preventOneYearRecovery': True,\n",
    "  'recoveryThreshold':      0.25,\n",
    "  'pvalThreshold':          0.05,\n",
    "  'bestModelProportion':    0.75, # LCMS uses 1.25\n",
    "  'minObservationsNeeded':  6\n",
    "}\n",
    "\n",
    "obands = orig_bands+['date'] if date_band else orig_bands\n",
    "bdict = {'orig':obands, 'spix':ixbands}\n",
    "\n",
    "## Filter on tiles (don't use aoi or aoi masked, export full tiles)\n",
    "tilesfc = ee.FeatureCollection(\"users/stevenf_csu/ecofor/tiles_utm36n\")\n",
    "\n",
    "tiles_path = r\"J:\\projects\\ECOFOR\\boundaries\\tiles_utm36n.gpkg\"\n",
    "tiles = gpd.read_file(tiles_path, driver='GPKG')\n",
    "aoi_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.gpkg\"\n",
    "aoi = gpd.read_file(aoi_path)\n",
    "tiles = tiles[tiles.intersects(aoi.unary_union)]\n",
    "\n",
    "rerun_failed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc687b-4d30-4db4-ac72-031eac961c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LT fitted for original band and spectral indices and export all years and bands together\n",
    "task_list = []\n",
    "for i, tile in tiles.iterrows():\n",
    "    tile_hv = tile['hv']\n",
    "    print(tile_hv)\n",
    "    tilegeo = tilesfc.filterMetadata('hv', 'equals', tile_hv).first().geometry()\n",
    "    \n",
    "    # Create composites\n",
    "    comps = time_series.annual_composites(tilegeo, starty, endy, startdoy, enddoy,\n",
    "                                          lxtools.sr_collection, time_series.medoid,\n",
    "                                          coll_kwargs, comp_kwargs, fill=fill)\n",
    "    \n",
    "    if date_band:\n",
    "        date_imgs = comps.select('date')\n",
    "        comps = comps.select(orig_bands)\n",
    "    \n",
    "    for k, bands in bdict.items():\n",
    "        if rerun_failed:\n",
    "            outname = 'lt_'+season+'_'+tile['hv']+'_'+k\n",
    "            if outname not in failed_files:\n",
    "                continue\n",
    "        if k=='spix':\n",
    "            comps = comps.map(lambda i: (lxtools.specixs(i, ixlist=ixbands)\n",
    "                                         .copyProperties(i, i.propertyNames())))\n",
    "\n",
    "        # Run LT and extract fit (all years all bands img coll)\n",
    "        imgs_fit = time_series.lt_fitted(comps, flip_bands=True, fit_band=None, **lt_kwargs)\n",
    "        imgs_fit = imgs_fit.sort('sytem:time_start')\n",
    "        \n",
    "        # stack to image with renamed bands for export\n",
    "        img = time_series.stack_annual(imgs_fit)\n",
    "        \n",
    "        # cast for export\n",
    "        img = img.multiply(1000).toInt16()\n",
    "        img = img.unmask(-32768)\n",
    "        \n",
    "        # export tile setup\n",
    "        outname = 'lt_'+season+'_'+tile['hv']+'_'+k\n",
    "        crs='epsg:32636'\n",
    "        scale = 30.0\n",
    "        dimx = int((tile['maxx'] - tile['minx'])/scale)\n",
    "        dimy = int((tile['maxy'] - tile['miny'])/scale)\n",
    "        dims = str(dimx)+'x'+str(dimy)\n",
    "        shardSize = 256\n",
    "        fileDimensions = (int(np.ceil(dimx / shardSize) * shardSize), int(np.ceil(dimy / shardSize) * shardSize))\n",
    "        transform = [scale, 0.0, float(tile['minx']), 0.0, -scale, float(tile['maxy'])]\n",
    "        nbands = (endy-starty+1) * len(bands)\n",
    "        \n",
    "        # to drive\n",
    "        task = ee.batch.Export.image.toDrive(image=img, \n",
    "                                             description=outname,\n",
    "                                             fileNamePrefix=outname,\n",
    "                                             folder = \"gee\",\n",
    "                                             dimensions=dims,\n",
    "                                             crs=crs,\n",
    "                                             crsTransform=str(transform),\n",
    "                                             maxPixels=float(dimx)*dimy*nbands,\n",
    "                                             fileDimensions=fileDimensions,\n",
    "                                             shardSize=shardSize\n",
    "                                            )\n",
    "        task_list.append(task)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213bd09-aa8c-4128-b06b-0c7ec0f84e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on tasks\n",
    "statuses = [task.status() for task in task_list]\n",
    "for status in statuses:\n",
    "    if 'start_timestamp_ms' in status.keys():\n",
    "        runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "    else:\n",
    "        runtime = 0\n",
    "    print(status['description'], status['state'], round(runtime, 2), 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56f93f-6e45-4c4a-a11e-7f98adc8a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get failed cells for rerunning\n",
    "# failed = [s['description'].split('_')[1] for s in statuses if s['state']=='FAILED']\n",
    "failed_files = [s['description'] for s in statuses if s['state']=='FAILED']\n",
    "failed_tiles = list(set([f.split('_')[1] for f in failed_files]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409ff4c-00f4-48d7-80bc-0a63246625fa",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325caa59-1826-46c4-91eb-03595a7e713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite tiles as a single stack of bands with a different file for each year.\n",
    "start_time = time.time()\n",
    "indir = r\"D:\\ecofor\\lt\\gee\"\n",
    "season = \"dry\" #\"wet\" # \n",
    "paths = glob(os.path.join(indir, \"*\"+season+\"*.tif\"))\n",
    "tile_dir = os.path.join(r\"D:\\ecofor\\lt\\tiles\", season)\n",
    "\n",
    "tiles = set([os.path.basename(path).split('_')[2] for path in paths])\n",
    "# tile_dict = {t:glob(os.path.join(indir, \"*\"+t+\"*.tif\")) for t in tiles}\n",
    "# tiles = list(tiles)[:2] # test subset\n",
    "\n",
    "orig_bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']\n",
    "spix_bands = ['ndvi', 'ndmi', 'nbr', 'tcg', 'tcw', 'tcb']\n",
    "\n",
    "# make dirs to hold all the tiles for a year\n",
    "# years = range(1984, 2023)\n",
    "years = [2022] # test subset\n",
    "for year in years:\n",
    "    os.makedirs(os.path.join(tile_dir, str(year)), exist_ok=True)\n",
    "\n",
    "for tile in tiles:\n",
    "    print(tile)\n",
    "    tpaths = [os.path.join(tile_dir, str(year), \"lt_\"+season+\"_\"+tile+\"_\"+str(year)+\".tif\") for year in years]\n",
    "    missing = [p for p in tpaths if not os.path.exists(p)]\n",
    "    if len(missing)==0:\n",
    "        print(tile, \"already completed.\")\n",
    "        continue\n",
    "    \n",
    "    orig_path = os.path.join(indir, \"lt_\"+season+\"_\"+tile+\"_orig.tif\")\n",
    "    spix_path = os.path.join(indir, \"lt_\"+season+\"_\"+tile+\"_spix.tif\")\n",
    "    \n",
    "    if not os.path.exists(orig_path):\n",
    "        print(orig_path, \"missing. Skipping tile.\")\n",
    "        continue\n",
    "    if not os.path.exists(spix_path):\n",
    "        print(spix_path, \"missing. Skipping tile.\")\n",
    "        continue    \n",
    "    \n",
    "    with rasterio.open(orig_path) as src:\n",
    "        orig = src.read()\n",
    "        orig_dsc = src.descriptions\n",
    "        prof = src.profile    \n",
    "    \n",
    "    with rasterio.open(spix_path) as src:\n",
    "        spix = src.read()\n",
    "        spix_dsc = src.descriptions\n",
    "        \n",
    "    prof['count'] = len(orig_bands+spix_bands)\n",
    "    prof['nodata'] = -32768\n",
    "    prof['interleave'] = 'band'\n",
    "    \n",
    "    def write_year(year):\n",
    "        print(tile, year)\n",
    "        # get array for year in the correct band order\n",
    "        orig_ix = [orig_dsc.index(str(year)+\"_\"+b) for b in orig_bands]\n",
    "        oarr = orig[orig_ix]\n",
    "        spix_ix = [spix_dsc.index(str(year)+\"_\"+b) for b in spix_bands]\n",
    "        sarr = spix[spix_ix]\n",
    "        arr = np.concatenate([oarr, sarr])\n",
    "        del oarr, sarr\n",
    "\n",
    "        # export tile for year\n",
    "        yr_dir = os.path.join(tile_dir, str(year))\n",
    "        yr_path = os.path.join(tile_dir, str(year), \"lt_\"+tile+\"_\"+str(year)+\".tif\")\n",
    "        with rasterio.open(yr_path, 'w', **prof) as dst:\n",
    "            dst.write(arr)\n",
    "            dst.descriptions = orig_bands + spix_bands\n",
    "        del arr\n",
    "    \n",
    "    Parallel(n_jobs=12)(delayed(write_year)(year) for year in years)\n",
    "    del orig, spix\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a78cf-db2e-413a-8c12-891545286fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make pyramids and stats for the images with concurrent threads\n",
    "tile_dir = r\"K:\\ECOFOR\\lt\\tiles\" #r\"D:\\ecofor\\lt\\tiles\"\n",
    "seasons = [\"wet\", \"dry\"]\n",
    "# years = range(1984,2022)\n",
    "years = [2022]\n",
    "\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "for season in seasons:\n",
    "    for year in years:\n",
    "        paths = glob(os.path.join(tile_dir, season, str(year), \"*.tif\"))  \n",
    "        for path in paths:\n",
    "            stat_cmd, pyr_cmd = pyr_stats(path, nodata=None, run=False)\n",
    "            if not os.path.exists(path+\".aux.xml\"):\n",
    "                stat_cmds.append(stat_cmd)\n",
    "            if not os.path.exists(path+\".ovr\"):\n",
    "                pyr_cmds.append(pyr_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ac8fd-386a-4103-93b1-8f11c2dd7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e03d68-d90e-4d7c-af8d-068becb7ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if tile stats are really necessary but approx stats are fast\n",
    "cmd_concurrent(stat_cmds, threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62d0a2-7f56-465a-a855-a3d844c76ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make VRTs\n",
    "basedir = r\"K:\\ECOFOR\\lt\" #r\"D:\\ecofor\\lt\"\n",
    "tile_dir = os.path.join(basedir, \"tiles\")\n",
    "seasons = [\"wet\", \"dry\"]\n",
    "# years = range(1984,2022)\n",
    "years = [2022]\n",
    "\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\"\n",
    "with rasterio.open(template_path) as src:\n",
    "    te = \" \".join([str(b) for b in src.bounds])\n",
    "\n",
    "for season in seasons:\n",
    "    indir = os.path.join(tile_dir, season)\n",
    "    vrt_dir = os.path.join(basedir, season)\n",
    "    os.makedirs(vrt_dir, exist_ok=True)\n",
    "\n",
    "    # don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(vrt_dir)\n",
    "\n",
    "    for y in years:\n",
    "        # create vrt\n",
    "        outname = \"lt_\"+season+\"_\"+str(y)+\".vrt\"\n",
    "        paths = glob(os.path.join(indir, str(y), \"*.tif\"))\n",
    "        paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "        paths.sort()\n",
    "#         cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "        cmd = \"gdalbuildvrt -te \" + te + \" \" + outname + \" \" + \" \".join(paths)\n",
    "        stdout = subprocess.check_output(cmd)\n",
    "\n",
    "        # set band descriptions\n",
    "        with rasterio.open(paths[0]) as src:\n",
    "            descs = src.descriptions\n",
    "        with rasterio.open(outname, 'r+') as src:\n",
    "            src.descriptions = descs\n",
    "\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2005eb-9f24-4926-959f-988ead1f20f6",
   "metadata": {},
   "source": [
    "**Tile-based pyramids and stats**  \n",
    "Creating the VRT after generating pyramids for tiles will automatically have the VRT use the tile pyramids, but calculating stats wipes this out so the line indicating there are virtual overviews needs to be added back again using gdaladdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de9ccd-b873-453e-a9e9-5b2e9af1837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pyramids and stats for VRTS\n",
    "basedir = r\"K:\\ECOFOR\\lt\" #r\"D:\\ecofor\\lt\"\n",
    "seasons = [\"wet\", \"dry\"]\n",
    "for season in seasons:\n",
    "    paths = glob(os.path.join(basedir, season, \"*.vrt\"))\n",
    "    stat_cmds = []\n",
    "    pyr_cmds = []\n",
    "    for path in paths:\n",
    "        stat_cmds.append('C:\\\\OSGeo4W64\\\\bin\\\\gdalinfo.exe -approx_stats ' + path) # for some reason the python environment version isn't working so use OSGeo\n",
    "        cmd_concurrent(stat_cmds, threads=6)\n",
    "        \n",
    "        pyr_cmds.append('gdaladdo --config VRT_VIRTUAL_OVERVIEWS YES ' + path) # 2 4 8 16 32\n",
    "        cmd_concurrent(pyr_cmds, threads=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f30fc-e301-4046-9c1c-5e1440e796de",
   "metadata": {},
   "source": [
    "**Dedicated pyramids and stats**  \n",
    "Dedicated pyramids read and display faster, but take a while to create and need to be recreated with added tiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f55e4f-1303-4767-8cec-a996505becaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdaladdo -ro --config COMPRESS_OVERVIEW ZSTD --config ZSTD_LEVEL_OVERVIEW 1 --config PREDICTOR_OVERVIEW 2 --config INTERLEAVE_OVERVIEW BAND --config GDAL_NUM_THREADS 16 --config GDAL_CACHEMAX 4096 path\n",
    "\n",
    "# helper functions\n",
    "def pyr_stats(path, run=True):\n",
    "    \"\"\"Set nodata (str of number or 'nan'). Calculate stats and pyramids for image at path (str).\"\"\"\n",
    "    cmds = {'stats':[], 'pyr':[]}\n",
    "    \n",
    "    stats_cmd = 'gdalinfo -approx_stats ' + path\n",
    "    if run:\n",
    "        result = subprocess.check_output(stats_cmd)\n",
    "    \n",
    "    if not os.path.exists(path+\".ovr\"):\n",
    "        pyr_cmd = 'gdaladdo -ro --config COMPRESS_OVERVIEW ZSTD --config ZSTD_LEVEL 1 --config PREDICTOR 2 --config INTERLEAVE_OVERVIEW BAND --config GDAL_NUM_THREADS 6 --config GDAL_CACHEMAX 4096 ' + path\n",
    "        if run:\n",
    "            result = subprocess.check_output(pyr_cmd)\n",
    "    else:\n",
    "        pyr_cmd = \"ECHO \" + path + \" completed\"\n",
    "    \n",
    "    return stats_cmd, pyr_cmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d923b73-2d5b-4bd7-8d0a-c143ff69513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_cmds, pyr_cmds = [], []\n",
    "paths = glob(r\"I:\\cmswest\\landtrendr\\usa\\*.vrt\")\n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, run=False)\n",
    "    stat_cmds.append(stat_cmd)\n",
    "    pyr_cmds.append(pyr_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47ae1e-744a-40d9-ba6b-1a86fe114884",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(stat_cmds, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de93f6-e080-4857-9de1-b444b2253328",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a4343-4f70-4ea4-af0d-a06ab3008e9c",
   "metadata": {},
   "source": [
    "# HLS S2 \n",
    "Check GEE data against NASA EarthData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a5319-f8a0-4a78-bc8e-ae961246e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.read_csv(r\"E:\\My Drive\\t36jut_ids.csv\")\n",
    "ndf = pd.read_csv(r\"C:\\Users\\stevenf\\Downloads\\3153634147-download.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b314a50-8c08-4f04-ad56-40af89a12514",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['fname'] = ndf[0].str.split('/').str[-1]\n",
    "ndf['datetime_str'] = ndf['fname'].str.split('.').str[3]\n",
    "ndf['datetime'] = pd.to_datetime(ndf['datetime_str'], format=\"%Y%jT%H%M%S\")\n",
    "ndf['date_str'] = ndf['datetime'].apply(lambda x: x.strftime(\"%Y%m%d\"))\n",
    "\n",
    "sdf = ndf.drop_duplicates('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20043395-9383-478b-ace0-b91a81359607",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['date_str'] = gdf['id'].str.split('_').str[1]\n",
    "gdf['datetime'] = pd.to_datetime(gdf['date_str'], format=\"%Y%m%dT%H%M%S\")\n",
    "gdf['date_str'] = gdf['datetime'].apply(lambda x: x.strftime(\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633484f-a30f-410f-a5a7-9c51b58e2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.merge(sdf, gdf, 'outer', on='date_str', indicator=True)\n",
    "mdf['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e3b91-4d87-43dc-a248-300e98ba7478",
   "metadata": {},
   "source": [
    "# TODO: Generate CCDC\n",
    "\n",
    "Creation of CCDC assets for tiles is currently done in javascript with users/stevenf/default/Projects/ecofor/run_ccdc_tile.  \n",
    "Extraction of CCDC coefficients for GEDI footprints is also done in javascript with users/stevenf/default/Projects/ecofor/ccdc_sample_extraction.  \n",
    "These should be ported to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba993fa3-1585-41a1-a4f8-b07737147a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6ccc86-0d4e-45ff-8112-fc6935539b26",
   "metadata": {},
   "source": [
    "# PALSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d3bf3-2a2a-4d09-8a5a-6b17da2fe975",
   "metadata": {},
   "outputs": [],
   "source": [
    "starty = 2007\n",
    "endy = 2022\n",
    "years = list(range(starty, 2011)) + list(range(2015, endy+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc274e3-f16c-454f-91e0-7e7144db6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter on tiles (don't use aoi or aoi masked, export full tiles)\n",
    "tilesfc = ee.FeatureCollection(\"users/stevenf/ecofor/mgrs_utm36n\")\n",
    "\n",
    "tiles_path = r\"J:\\projects\\ECOFOR\\boundaries\\mgrs_utm36n.gpkg\"\n",
    "tiles = gpd.read_file(tiles_path, driver='GPKG')\n",
    "# aoi_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.gpkg\"\n",
    "# aoi = gpd.read_file(aoi_path)\n",
    "# tiles = tiles[tiles.intersects(aoi.unary_union)]\n",
    "\n",
    "# testing\n",
    "tiles = tiles[tiles['hv'].isin([\"0101\", \"0102\", \"0103\"])] #tiles[5:]\n",
    "years = [2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033a766-2136-4465-8b05-74a958fe2d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load collection into linear units and apply multitemporal speckle filtering\n",
    "imgs = ee.ImageCollection(\"JAXA/ALOS/PALSAR/YEARLY/SAR_EPOCH\")\n",
    "imgs = imgs.map(lambda i: sar.dn_to_pow(i, 'PALSAR_Yearly'))\n",
    "# TODO: If cross-calibration is necessary then run speckle filtering separately for PALSAR-1 AND PALSAR-2 or cross-calibrate first.\n",
    "imgs = sar.MultiTemporal_Filter(imgs, sfilter=\"BOXCAR\", ksize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90cde1-d479-442d-a049-401b7b684c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_list = []\n",
    "for year in years:\n",
    "    img = ee.Image(imgs.filterDate(str(year), str(year+1)).first())\n",
    "    \n",
    "    img = sar.pow_to_db(img)             # Convert linear power to dB\n",
    "    img = sar.epoch_to_doy(img, 'epoch') # Get day of year band\n",
    "    \n",
    "    # TODO: Calibrate Palsar1 and Palsar2?\n",
    "    \n",
    "    img = img.toFloat()\n",
    "    img = img.resample('bilinear')\n",
    "    img = img.unmask(-9999.0)\n",
    "    \n",
    "    # Export for year and tile\n",
    "    for i, tile in tiles.iterrows():\n",
    "        tile_hv = tile['hv']\n",
    "        print(year, tile_hv)\n",
    "        tilegeo = tilesfc.filterMetadata('hv', 'equals', tile_hv).first().geometry()\n",
    "\n",
    "        # export tile setup\n",
    "        outname = 'palsar_'+str(year)+\"_\"+tile['hv']\n",
    "        crs='epsg:32636'\n",
    "        scale = 30.0\n",
    "        dimx = int((tile['maxx'] - tile['minx'])/scale)\n",
    "        dimy = int((tile['maxy'] - tile['miny'])/scale)\n",
    "        dims = str(dimx)+'x'+str(dimy)\n",
    "        shardSize = 256\n",
    "        fileDimensions = (int(np.ceil(dimx / shardSize) * shardSize), int(np.ceil(dimy / shardSize) * shardSize))\n",
    "        transform = [scale, 0.0, float(tile['minx']), 0.0, -scale, float(tile['maxy'])]\n",
    "        nbands = 5\n",
    "        \n",
    "        # to drive\n",
    "        task = ee.batch.Export.image.toDrive(image=img, \n",
    "                                             description=outname,\n",
    "                                             fileNamePrefix=outname,\n",
    "                                             folder = \"gee\",\n",
    "                                             dimensions=dims,\n",
    "                                             crs=crs,\n",
    "                                             crsTransform=str(transform),\n",
    "                                             maxPixels=float(dimx)*dimy*nbands,\n",
    "                                             fileDimensions=fileDimensions,\n",
    "                                             shardSize=shardSize\n",
    "                                            )\n",
    "        task_list.append(task)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d3746-5cf1-4871-96f8-7f4428466d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check on tasks\n",
    "statuses = [task.status() for task in task_list]\n",
    "for status in statuses:\n",
    "    if 'start_timestamp_ms' in status.keys():\n",
    "        runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "    else:\n",
    "        runtime = 0\n",
    "    print(status['description'], status['state'], round(runtime, 2), 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6746edf-26e5-4b14-a493-a7780f82f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pyramids and stats for the images with concurrent threads\n",
    "tile_dir = r\"H:\\ECOFOR\\palsar\\tiles\"\n",
    "\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "paths = glob(os.path.join(tile_dir, \"*.tif\"))  \n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, nodata=-9999.0, run=False)\n",
    "    if not os.path.exists(path+\".aux.xml\"):\n",
    "        stat_cmds.append(stat_cmd)\n",
    "    if not os.path.exists(path+\".ovr\"):\n",
    "        pyr_cmds.append(pyr_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619c9ba-02b1-4415-aff1-e3b1fb74e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=6)\n",
    "cmd_concurrent(stat_cmds, threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479f65a-dabf-4114-a5b9-98f91e1bbe0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make VRTs\n",
    "basedir = r\"H:\\ECOFOR\\palsar\"\n",
    "tile_dir = os.path.join(basedir, \"tiles\")\n",
    "years = list(range(starty, 2011)) + list(range(2015, endy+1))\n",
    "# years = [2022]\n",
    "\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\gknp_utm36n_mgrs.tif\"\n",
    "with rasterio.open(template_path) as src:\n",
    "    te = \" \".join([str(b) for b in src.bounds])\n",
    "\n",
    "indir = tile_dir\n",
    "vrt_dir = basedir\n",
    "\n",
    "# don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "cwd = os.getcwd()\n",
    "os.chdir(vrt_dir)\n",
    "\n",
    "for y in years:\n",
    "    # create vrt\n",
    "    outname = \"palsar_\"+str(y)+\".vrt\"\n",
    "    paths = glob(os.path.join(indir, \"*_\"+str(y)+\"_*.tif\"))\n",
    "    paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "    paths.sort()\n",
    "#         cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "    cmd = \"gdalbuildvrt -te \" + te + \" \" + outname + \" \" + \" \".join(paths)\n",
    "    stdout = subprocess.check_output(cmd)\n",
    "\n",
    "    # set band descriptions\n",
    "    with rasterio.open(paths[0]) as src:\n",
    "        descs = src.descriptions\n",
    "    with rasterio.open(outname, 'r+') as src:\n",
    "        src.descriptions = descs\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37498c1f-ac9b-4708-89b9-074be4edd73f",
   "metadata": {},
   "source": [
    "# PlanetScope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8ee29-cc42-4e81-89f9-6378fe1cc07a",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## LT scale and tiling\n",
    "Export reduced resolution PlanetScope monthly basemap band values, spectral indices, and texture indices for the dry season.\n",
    "\n",
    "After investigating the best month, bands, and texture indice parameters through vizualization in GEE with this script (https://code.earthengine.google.com/2573a0458fb1a92015f732b1fd5da499). I decided on the following parameters:  \n",
    "1. May - less likely to have clouds and NIR shows greater spatial variability for trees due to shadows. Red is more similar across months.\n",
    "2. Bands - original bands and NDVI\n",
    "3. Texture - Red and NIR bands for May, all indices, size of 2 (5x5 window), resample to 30 m using mean reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c9462-864a-4ce0-bffc-889a5aaa90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sources\n",
    "imgs = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\")\n",
    "gedi = ee.FeatureCollection('users/stevenf/ecofor/GEDI_2AB_2019to2023_leafon_sampy500m_shotdate')\n",
    "\n",
    "# Options\n",
    "starty = 2016\n",
    "endy = 2024\n",
    "\n",
    "## Filter on tiles (don't use aoi or aoi masked, export full tiles)\n",
    "tilesfc = ee.FeatureCollection(\"users/stevenf_csu/ecofor/tiles_utm36n\")\n",
    "\n",
    "tiles_path = r\"J:\\projects\\ECOFOR\\boundaries\\tiles_utm36n.gpkg\"\n",
    "tiles = gpd.read_file(tiles_path, driver='GPKG')\n",
    "aoi_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.gpkg\"\n",
    "aoi = gpd.read_file(aoi_path)\n",
    "tiles = tiles[tiles.intersects(aoi.unary_union)]\n",
    "\n",
    "rerun_failed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8071e-5b48-448a-8357-55b631804ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LT fitted for original band and spectral indices and export all years and bands together\n",
    "task_list = []\n",
    "fc_task_list = []\n",
    "for year in range(starty, endy+1):        \n",
    "    # Get monthly/biannual basemap image\n",
    "    start_date = str(year)+'-05-02'\n",
    "    end_date = str(year)+'-06-02'\n",
    "    date_filter = ee.Filter.dateRangeContains(leftValue=ee.DateRange(start_date, end_date), rightField='system:time_end')\n",
    "    img = imgs.filter(date_filter).first()\n",
    "\n",
    "    # Calculate spectral indices\n",
    "    ndvi = img.normalizedDifference(['N', 'R']).rename('ndvi')\n",
    "\n",
    "    # Get texture indices\n",
    "    glcm_bands = ['N', 'R']\n",
    "    glcm = img.select(glcm_bands).glcmTexture(size= 2, average=True)\n",
    "\n",
    "    keep_ix = ['asm', 'contrast', 'corr', 'var', 'idm', 'ent', 'diss', 'inertia']\n",
    "    texture_bands = [b+'_'+i for b in glcm_bands for i in keep_ix]\n",
    "    glcm = glcm.select(texture_bands)\n",
    "\n",
    "    # Merge all\n",
    "    img = ee.Image.cat(img, ndvi, glcm).toFloat()\n",
    "\n",
    "    # Extract mean over gedi footprints\n",
    "    if year >= 2019:\n",
    "        gedi_y = gedi.filter(ee.Filter.equals('rain_year', year))\n",
    "        gedi_y = gedi_y.map(lambda f: f.buffer(12.5))\n",
    "        fc = img.reduceRegions(gedi_y, ee.Reducer.mean())\n",
    "        \n",
    "        fc = fc.map(lambda f: f.setGeometry(None))\n",
    "        outname = 'GEDI_2AB_leafon_sampy500m_PS_'+str(year)\n",
    "        fc_task = ee.batch.Export.table.toDrive(fc,\n",
    "                                              description=outname,\n",
    "                                              folder='gee',\n",
    "                                              fileNamePrefix=outname,\n",
    "                                              fileFormat='CSV'\n",
    "                                             )\n",
    "        fc_task_list.append(fc_task)\n",
    "        fc_task.start()\n",
    "\n",
    "    # Upsample image for export\n",
    "    img = img.reduceResolution(reducer=ee.Reducer.mean(), maxPixels=1024)\n",
    "    img = img.unmask(-99999)\n",
    "    \n",
    "    # Export tiles\n",
    "    for i, tile in tiles.iterrows():\n",
    "        tile_hv = tile['hv']\n",
    "        print(tile_hv, year)\n",
    "        tilegeo = tilesfc.filterMetadata('hv', 'equals', tile_hv).first().geometry()\n",
    "\n",
    "        # export tile setup\n",
    "        outname = 'ps_'+str(year)+'_'+tile['hv']\n",
    "        crs='epsg:32636'\n",
    "        scale = 30.0\n",
    "        dimx = int((tile['maxx'] - tile['minx'])/scale)\n",
    "        dimy = int((tile['maxy'] - tile['miny'])/scale)\n",
    "        dims = str(dimx)+'x'+str(dimy)\n",
    "        shardSize = 256\n",
    "        fileDimensions = (int(np.ceil(dimx / shardSize) * shardSize), int(np.ceil(dimy / shardSize) * shardSize))\n",
    "        transform = [scale, 0.0, float(tile['minx']), 0.0, -scale, float(tile['maxy'])]\n",
    "        nbands = 4 + 1 + len(texture_bands) # 4 orig bands + 1 ndvi + selected texture bands\n",
    "\n",
    "        # to drive\n",
    "        task = ee.batch.Export.image.toDrive(image=img, \n",
    "                                             description=outname,\n",
    "                                             fileNamePrefix=outname,\n",
    "                                             folder = \"gee\",\n",
    "                                             dimensions=dims,\n",
    "                                             crs=crs,\n",
    "                                             crsTransform=str(transform),\n",
    "                                             maxPixels=float(dimx)*dimy*nbands,\n",
    "                                             fileDimensions=fileDimensions,\n",
    "                                             shardSize=shardSize\n",
    "                                            )\n",
    "        task_list.append(task)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005fde7-753e-4e52-889e-1317736984ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check on tasks\n",
    "statuses = [task.status() for task in task_list]\n",
    "for status in statuses:\n",
    "    if 'start_timestamp_ms' in status.keys():\n",
    "        runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "    else:\n",
    "        runtime = 0\n",
    "    print(status['description'], status['state'], round(runtime, 2), 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2739f27-d000-4efe-96a5-34b421740a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check on tasks\n",
    "statuses = [task.status() for task in fc_task_list]\n",
    "for status in statuses:\n",
    "    if 'start_timestamp_ms' in status.keys():\n",
    "        runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "    else:\n",
    "        runtime = 0\n",
    "    print(status['description'], status['state'], round(runtime, 2), 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b7aad-13d3-4816-a8d4-003556ef1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pyramids and stats for the images with concurrent threads\n",
    "tile_dir = r\"I:\\ECOFOR\\planet\\lt_tiling_scheme\"\n",
    "\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "paths = glob(os.path.join(tile_dir, \"*.tif\"))  \n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, nodata=-99999.0, run=False)\n",
    "    if not os.path.exists(path+\".aux.xml\"):\n",
    "        stat_cmds.append(stat_cmd)\n",
    "    if not os.path.exists(path+\".ovr\"):\n",
    "        pyr_cmds.append(pyr_cmd)\n",
    "\n",
    "cmd_concurrent(pyr_cmds, threads=12)\n",
    "cmd_concurrent(stat_cmds, threads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e985d1c-56ff-4f51-91df-a99a1cbe5643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make VRTs\n",
    "basedir = r\"I:\\ECOFOR\\planet\"\n",
    "tile_dir = os.path.join(basedir, \"lt_tiling_scheme\")\n",
    "years = list(range(starty, endy))\n",
    "# years = [2022]\n",
    "\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\"\n",
    "with rasterio.open(template_path) as src:\n",
    "    te = \" \".join([str(b) for b in src.bounds])\n",
    "\n",
    "indir = tile_dir\n",
    "vrt_dir = basedir\n",
    "\n",
    "# don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "cwd = os.getcwd()\n",
    "os.chdir(vrt_dir)\n",
    "\n",
    "for y in years:\n",
    "    # create vrt\n",
    "    outname = \"ps_\"+str(y)+\".vrt\"\n",
    "    paths = glob(os.path.join(indir, \"*_\"+str(y)+\"_*.tif\"))\n",
    "    paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "    paths.sort()\n",
    "#         cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "    cmd = \"gdalbuildvrt -te \" + te + \" \" + outname + \" \" + \" \".join(paths)\n",
    "    stdout = subprocess.check_output(cmd)\n",
    "\n",
    "    # set band descriptions\n",
    "    with rasterio.open(paths[0]) as src:\n",
    "        descs = src.descriptions\n",
    "    with rasterio.open(outname, 'r+') as src:\n",
    "        src.descriptions = descs\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54514d81-982a-452d-896d-ce436ce1c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pyramids and stats for VRTS\n",
    "basedir = r\"I:\\ECOFOR\\planet\"\n",
    "paths = glob(os.path.join(basedir, \"*.vrt\"))\n",
    "\n",
    "stat_cmds = []\n",
    "pyr_cmds = []\n",
    "for path in paths:\n",
    "    stat_cmds.append('C:\\\\OSGeo4W\\\\bin\\\\gdalinfo.exe -approx_stats ' + path) # for some reason the python environment version isn't working so use OSGeo\n",
    "    # stat_cmds.append('gdalinfo -approx_stats ' + path) # for some reason the python environment version isn't working so use OSGeo\n",
    "    cmd_concurrent(stat_cmds, threads=6)\n",
    "\n",
    "    pyr_cmds.append('gdaladdo --config VRT_VIRTUAL_OVERVIEWS YES ' + path) # 2 4 8 16 32\n",
    "    cmd_concurrent(pyr_cmds, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23774e-bc3e-4ac8-a718-61fc14286222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge individual GEDI csvs\n",
    "indir = r\"I:\\ECOFOR\\gedi\\extracted\\planetscope\"\n",
    "paths = glob(os.path.join(indir, \"*.csv\"))\n",
    "outpath = r\"I:\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_planetscope.csv\"\n",
    "\n",
    "df = pd.concat([pd.read_csv(p) for p in paths])\n",
    "df = df.rename(columns={'shot_num':'shot_number'})\n",
    "\n",
    "drop_cols = [\"system:index\", \"delta_time\", \"millis\", \"rain_year\", \"year\", \".geo\"]\n",
    "df = df.drop(columns=drop_cols)\n",
    "df.to_csv(outpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeff4d6-b2a1-4d7b-aa10-889c5726879c",
   "metadata": {},
   "source": [
    "## Mosaic original quads\n",
    "Sort and mosaic the quads downloaded through ArcGIS plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159deb39-fe0c-457b-ad32-7b0fb8b8d172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the tiles into monthly folders\n",
    "indir = r\"I:\\ECOFOR\\planet\\normalized_analytic_monthly_quads\"\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "\n",
    "months = set([os.path.basename(p)[:7] for p in paths])\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(indir)\n",
    "\n",
    "for month in months:\n",
    "    mpaths = glob(os.path.join(indir, month+\"*.tif\"))\n",
    "    outdir = os.path.join(indir, month)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    for path in mpaths:\n",
    "        outpath = os.path.join(outdir, os.path.basename(path))\n",
    "        os.rename(path, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52a873-05b6-43dd-a662-54c2b5ba07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vrt mosaics for all folders\n",
    "basedir = r\"I:\\ECOFOR\\planet\\normalized_analytic_monthly_quads\"\n",
    "indirs = glob(os.path.join(basedir, \"*/\"))\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(basedir)\n",
    "\n",
    "months = [d for d in os.listdir(basedir) if os.path.isdir(os.path.join(basedir, d))]\n",
    "\n",
    "for month in months:\n",
    "    outname = \"ps_\"+month+\".vrt\"\n",
    "    paths = glob(os.path.join(basedir, month, \"*.tif\"))\n",
    "    paths = [os.path.relpath(p, basedir) for p in paths]\n",
    "    paths.sort()\n",
    "    cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)\n",
    "    stdout = subprocess.check_output(cmd)\n",
    "    \n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2e49a-bc54-4e33-a4f9-5b4473558209",
   "metadata": {},
   "source": [
    "# Topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b760980-fa97-4136-aa01-f5778aaae3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topography\n",
    "elevation = ee.Image(\"NASA/NASADEM_HGT/001\").select([\"elevation\"], [\"elev\"]).resample('bicubic')\n",
    "aspect = ee.Terrain.aspect(elevation).multiply(np.pi/180.).rename('aspect')\n",
    "northness = aspect.cos().rename('northness')\n",
    "eastness = aspect.sin().rename('eastness')\n",
    "slope = ee.Terrain.slope(elevation)\n",
    "\n",
    "# Stage 1976: slope proportion * cos or sin of aspect; Taken from Evan's SpatialEco R library\n",
    "slope_prop = slope.expression(\"tan(b(0) * pi/180)\", {\"pi\":np.pi}).rename(\"slope_prop\")\n",
    "slope_pct = slope_prop.multiply(100).rename(\"slope_pct\")\n",
    "slope_prop = slope_prop.where(slope_prop.gt(1), 1.01)\n",
    "slope_east = slope_prop.multiply(eastness).rename('slope_east')\n",
    "slope_north = slope_prop.multiply(northness).rename('slope_north')\n",
    "\n",
    "# TRASP - Roberts and Cooper 1989\n",
    "trasp = aspect.expression(\"(1-(cos(b(0)-d))) / 2\", {\"d\":(30 * np.pi/180)}).rename(\"trasp\")\n",
    "\n",
    "# Topographic position index\n",
    "tpi90 = elevation.subtract(elevation.focal_mean(radius=90, units='meters')).rename('tpi90')\n",
    "tpi300 = elevation.subtract(elevation.focal_mean(radius=300, units='meters')).rename('tpi300')\n",
    "tpi990 = elevation.subtract(elevation.focal_mean(radius=990, units='meters')).rename('tpi990')\n",
    "\n",
    "# Indices from Theobald and CSP\n",
    "mtpi = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_mTPI\").rename('mtpi').resample('bicubic')\n",
    "chili = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_CHILI\").rename('chili').resample('bicubic')\n",
    "tdiv = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_topoDiversity\").rename('tdiv').resample('bicubic')\n",
    "# physd = ee.Image('CSP/ERGo/1_0/US/physioDiversity').rename('physd').resample('bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001105d-6475-49d2-a5fe-d8cd295c4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export each as a separate image\n",
    "images = [elevation, northness, eastness, slope_pct, slope_east, slope_north, trasp, tpi90, tpi300, tpi990, tdiv, mtpi, chili]\n",
    "task_list = []\n",
    "  \n",
    "# get output transform and dims\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\"\n",
    "with rasterio.open(template_path) as src:\n",
    "    transform = src.transform\n",
    "    w, h = src.width, src.height\n",
    "transform = list(transform)[:-3]\n",
    "dims = str(w)+\"x\"+str(h)\n",
    "shardSize = 256\n",
    "crs=\"epsg:32636\"\n",
    "fileDimensions = (int(np.ceil(w / shardSize) * shardSize), int(np.ceil(h / shardSize) * shardSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe3baf-0c7e-451f-a919-c014efb70453",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    bname = image.bandNames().getInfo()[0]\n",
    "    outname = \"topo_\"+bname\n",
    "    image = image.float().unmask(-9999)\n",
    "\n",
    "    # to drive\n",
    "    task = ee.batch.Export.image.toDrive(image=image, \n",
    "                                         description=outname,\n",
    "                                         fileNamePrefix=outname,\n",
    "                                         folder=\"gee\",\n",
    "                                         dimensions=dims,\n",
    "                                         crs=crs,\n",
    "                                         crsTransform=str(transform),\n",
    "                                         maxPixels=fileDimensions[0]*fileDimensions[1],\n",
    "#                                          fileDimensions=fileDimensions\n",
    "                                        )\n",
    "    task_list.append(task)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ca8eb-cd4d-488c-9339-8422bc493102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_list = ee.batch.Task.list()\n",
    "statuses = [task.status() for task in task_list]\n",
    "for status in statuses:\n",
    "    if 'start_timestamp_ms' in status.keys():\n",
    "        runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "    else:\n",
    "        runtime = 0\n",
    "    print(status['description'], status['state'], round(runtime, 2), 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb66f6-1b38-406b-932f-fce4fc1eb6f2",
   "metadata": {},
   "source": [
    "**Prep topo images**  \n",
    "Note some images have been accidently exported with one extra pixel in each direction, so these may need to be fixed with rio warp in.tif out.tif --like template.tif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbe0b3-4afb-4d57-a30e-978f441c6a32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that images match\n",
    "topo_dir = r\"J:\\projects\\ECOFOR\\topo\"\n",
    "paths = glob(os.path.join(topo_dir, \"*.tif\"))\n",
    "for path in paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        print(path)\n",
    "        print(src.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd73446-9e38-4143-b98e-d18fab579ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pyramids and calc stats for the source data\n",
    "paths = glob(os.path.join(topo_dir, \"*.tif\"))\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, nodata='-9999', run=False)\n",
    "    stat_cmds.append(stat_cmd)\n",
    "    pyr_cmds.append(pyr_cmd)\n",
    "    pyr_cmds = [cmd for cmd in pyr_cmds if cmd is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f697dab-d124-4ee0-9ec0-e2b165e60391",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(stat_cmds, threads=4)#30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebd9d8-0d67-400f-96fb-be65061b66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=4)#30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33878c-67d2-4414-b071-4e619786b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vrt for when applying model\n",
    "topo_paths = glob(topo_dir + r\"\\*.tif\")\n",
    "vrt_path = os.path.join(topo_dir, \"topo_all.vrt\")\n",
    "cmd = \"gdalbuildvrt -separate -srcnodata -9999 -vrtnodata -9999 \" + vrt_path + \" \" + \" \".join(topo_paths)\n",
    "stdout = subprocess.check_output(cmd)\n",
    "\n",
    "# set band descriptions\n",
    "with rasterio.open(vrt_path, 'r+') as src:\n",
    "    fs = src.files[1:]\n",
    "    src.descriptions = [os.path.basename(f)[:-4].replace('topo_', '') for f in fs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1f878-0243-49a0-9d76-e2eafd1a7140",
   "metadata": {},
   "source": [
    "# Climate\n",
    "\n",
    "Warp WorldClim v2.1 BIO variables to match the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d3d1a-0d3c-4a01-9a90-a43fc9936781",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = r\"J:\\data\\WorldClim_v2.1\"\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\"\n",
    "clim_dir = r\"J:\\projects\\ECOFOR\\climate\"\n",
    "\n",
    "for path in paths:\n",
    "    outpath = os.path.join(clim_dir, os.path.basename(path))\n",
    "    cmd_list = [\"rio\", \"warp\", path, outpath, \"--like\", template_path]\n",
    "    proc = subprocess.run(cmd_list, capture_output=True)\n",
    "    print(proc.stdout)\n",
    "    print(proc.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec122b7c-233c-4098-870a-47be48e505c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(r\"J:\\projects\\ECOFOR\\climate\\wc2.1_30s_bio_1.tif\") as src:\n",
    "    print(src.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e01d4-71f9-46d2-bab6-526342062ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31fc9cd-d7f7-419f-af4f-6504846ef25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pyramids and calc stats for the source data\n",
    "paths = glob(os.path.join(clim_dir, \"*.tif\"))\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, run=False) #nodata='-9999', \n",
    "    stat_cmds.append(stat_cmd)\n",
    "    pyr_cmds.append(pyr_cmd)\n",
    "    pyr_cmds = [cmd for cmd in pyr_cmds if cmd is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df29ebc-d8ff-4def-a2dc-812f464e794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(stat_cmds, threads=4)#30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10234f-b686-473f-a94f-1031550a7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=4)#30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4aa3db-3641-483d-9d92-e22a2afbccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vrt for when applying model\n",
    "clim_paths = glob(clim_dir + r\"\\*.tif\")\n",
    "vrt_path = os.path.join(clim_dir, \"worldclim_bio_all.vrt\")\n",
    "cmd = \"gdalbuildvrt -separate  \" + vrt_path + \" \" + \" \".join(clim_paths) #-srcnodata -9999 -vrtnodata -9999\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a66000-ed13-4edf-9a16-40dd03eac5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7db030-8fc6-4f3d-be9b-79508af026fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set band descriptions\n",
    "with rasterio.open(vrt_path, 'r+') as src:\n",
    "    fs = src.files[1:]\n",
    "    src.descriptions = ['_'.join(os.path.basename(f)[:-4].split('_')[-2:]) for f in fs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b114a90-56bf-4fd0-b2e0-7269fb63e2f1",
   "metadata": {},
   "source": [
    "# Soils  \n",
    "Using 30 m iSDA soils for now but this using Landsat as a predictor. SoilsGrid also uses Landsat and MODIS as a predictor. In both cases there are too many layers so I just selected a few almost at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006739d-7c5e-444d-ba9a-75d875673889",
   "metadata": {},
   "outputs": [],
   "source": [
    "orgc = ee.Image(\"ISDASOIL/Africa/v1/carbon_organic\").divide(10).exp().subtract(1)\n",
    "orgc_mean020 = orgc.select('mean_0_20')\n",
    "orgc_mean2050 = orgc.select('mean_20_50')\n",
    "cat = ee.Image(\"ISDASOIL/Africa/v1/cation_exchange_capacity\").divide(10).exp().subtract(1)\n",
    "cat_mean020 = orgc.select('mean_0_20')\n",
    "cat_mean2050 = orgc.select('mean_20_50')\n",
    "nitrogen = ee.Image(\"ISDASOIL/Africa/v1/nitrogen_total\").divide(100).exp().subtract(1)\n",
    "nitrogen_mean020 = orgc.select('mean_0_20')\n",
    "nitrogen_mean2050 = orgc.select('mean_20_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf9856-7825-4805-b75e-19a63d3bdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {'orgc':ee.Image(\"ISDASOIL/Africa/v1/carbon_organic\").divide(10).exp().subtract(1),\n",
    "          'cat':ee.Image(\"ISDASOIL/Africa/v1/cation_exchange_capacity\").divide(10).exp().subtract(1),\n",
    "          'nitro':ee.Image(\"ISDASOIL/Africa/v1/nitrogen_total\").divide(100).exp().subtract(1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e0c0e-4453-4a1c-a474-ece229f05ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export each band from each image as a separate tif\n",
    "task_list = []\n",
    "  \n",
    "# get output transform and dims\n",
    "template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\"\n",
    "with rasterio.open(template_path) as src:\n",
    "    transform = src.transform\n",
    "    w, h = src.width, src.height\n",
    "transform = list(transform)[:-3]\n",
    "dims = str(w)+\"x\"+str(h)\n",
    "shardSize = 256\n",
    "crs=\"epsg:32636\"\n",
    "fileDimensions = (int(np.ceil(w / shardSize) * shardSize), int(np.ceil(h / shardSize) * shardSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab449b85-34bf-4ac0-8c98-b34600ac216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['mean_0_20', 'mean_20_50']\n",
    "for var, image in images.items():\n",
    "    for band in bands:\n",
    "        layer = image.select(band)\n",
    "        bname = layer.bandNames().getInfo()[0].replace('_','')\n",
    "        outname = \"soil_\"+var+'_'+bname\n",
    "        layer = layer.float().unmask(-9999)\n",
    "\n",
    "        # to drive\n",
    "        task = ee.batch.Export.image.toDrive(image=layer, \n",
    "                                             description=outname,\n",
    "                                             fileNamePrefix=outname,\n",
    "                                             folder=\"gee\",\n",
    "                                             dimensions=dims,\n",
    "                                             crs=crs,\n",
    "                                             crsTransform=str(transform),\n",
    "                                             maxPixels=fileDimensions[0]*fileDimensions[1],\n",
    "    #                                          fileDimensions=fileDimensions\n",
    "                                            )\n",
    "        task_list.append(task)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a28d7-d447-41b2-bbe3-bff8e6e3e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_list = ee.batch.Task.list()\n",
    "statuses = [task.status() for task in task_list]\n",
    "for status in statuses:\n",
    "    if 'start_timestamp_ms' in status.keys():\n",
    "        runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "    else:\n",
    "        runtime = 0\n",
    "    print(status['description'], status['state'], round(runtime, 2), 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384d92f-f951-4c3d-b6fa-7741b342f3ce",
   "metadata": {},
   "source": [
    "**Prep soil images**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455b24e-2e70-4083-9b71-973cb2e3f301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that images match\n",
    "soil_dir = r\"J:\\projects\\ECOFOR\\soils\"\n",
    "paths = glob(os.path.join(soil_dir, \"*.tif\"))\n",
    "for path in paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        print(path)\n",
    "        print(src.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0eb04-9b01-42e1-909a-cc3edea80cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pyramids and calc stats for the source data\n",
    "paths = glob(os.path.join(soil_dir, \"*.tif\"))\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, nodata='-9999', run=False)\n",
    "    stat_cmds.append(stat_cmd)\n",
    "    pyr_cmds.append(pyr_cmd)\n",
    "    pyr_cmds = [cmd for cmd in pyr_cmds if cmd is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de33dc6-f314-4751-bc17-68f5954ab672",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(stat_cmds, threads=4)#30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3b21e-b959-49fe-a828-dd481fa159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=4)#30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d5bb5-7294-4a9c-b32e-e19024ea1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vrt for when applying model\n",
    "topo_paths = glob(soil_dir + r\"\\*.tif\")\n",
    "vrt_path = os.path.join(soil_dir, \"soil_all.vrt\")\n",
    "cmd = \"gdalbuildvrt -separate -srcnodata -9999 -vrtnodata -9999 \" + vrt_path + \" \" + \" \".join(topo_paths)\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b5dcd-d06e-4fb7-b46d-6b0f2db56b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set band descriptions\n",
    "with rasterio.open(vrt_path, 'r+') as src:\n",
    "    fs = src.files[1:]\n",
    "    src.descriptions = [os.path.basename(f)[:-4].replace('soil_', '') for f in fs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13accf7a-d8a7-4f59-a44d-562bfcd3db87",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# DEMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd682d65-5135-4436-a0ff-e19480484d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2018 photogrammetric 1 m\n",
    "Subtract DSM from DTM to generate CHM, and extract values in relevant areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a694c-c4ff-4a71-995c-97af33f81a81",
   "metadata": {},
   "source": [
    "### CHM\n",
    "Subtract DSM from DTM tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e5481-3ed2-47eb-a8ef-785757440572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsm_paths = glob(r\"E:\\ECOFOR\\dem\\dsm_025m\\*.tif\")\n",
    "# dsm_paths = dsm_paths[:1]\n",
    "\n",
    "for dsm_path in dsm_paths:\n",
    "    dtm_path = dsm_path.replace('dsm', 'dtm')\n",
    "    chm_path = dsm_path.replace('dsm', 'chm')\n",
    "    \n",
    "    if os.path.exists(chm_path):\n",
    "        print(chm_path, \"exists\")\n",
    "        continue\n",
    "    \n",
    "    # check dimensions first\n",
    "    with rasterio.open(dsm_path) as src:\n",
    "        h = src.height\n",
    "        w = src.width\n",
    "    with rasterio.open(dtm_path) as src:\n",
    "        h2 = src.height\n",
    "        w2 = src.width\n",
    "    if (h!=h2) or (w!=w2):\n",
    "        print(\"Dims different.\", \"Skipping\", dsm_path)\n",
    "        continue\n",
    "    \n",
    "    print(\"Processing\", dsm_path)\n",
    "    \n",
    "    with rasterio.open(dsm_path) as src:\n",
    "        dsm = src.read(1)\n",
    "        dsm_nodata = dsm==src.nodata\n",
    "        profile = src.profile\n",
    "        \n",
    "    with rasterio.open(dtm_path) as src:\n",
    "        dtm = src.read(1)\n",
    "        dtm_nodata = dtm==src.nodata\n",
    "    \n",
    "    chm = dsm - dtm\n",
    "    chm[dsm_nodata | dtm_nodata] = profile['nodata']\n",
    "    \n",
    "    with rasterio.open(chm_path, 'w', **profile) as dst:\n",
    "        dst.write(chm, 1)\n",
    "    \n",
    "    del dsm, dtm, chm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356fe52-9fda-46b2-9b85-53453ea387b8",
   "metadata": {},
   "source": [
    "### Generate Pyramids and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd81f4fe-3fcb-41b0-90f3-a3059825af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def pyr_stats(path, nodata=None, run=True):\n",
    "    \"\"\"Set nodata (str of number or 'nan'). Calculate stats and pyramids for image at path (str).\"\"\"\n",
    "    cmds = {'stats':[], 'pyr':[]}\n",
    "    if nodata:\n",
    "        cmd = 'rio edit-info --nodata ' + str(nodata) + ' ' + path\n",
    "        result = subprocess.check_output(cmd)\n",
    "    \n",
    "    stats_cmd = 'gdalinfo -approx_stats --config GDAL_PAM_ENABLED TRUE ' + path\n",
    "    if run:\n",
    "        result = subprocess.check_output(stats_cmd)\n",
    "    \n",
    "    if not os.path.exists(path[:-4]+\".ovr\"):\n",
    "        pyr_cmd = 'gdaladdo -ro --config COMPRESS_OVERVIEW ZSTD --config ZSTD_LEVEL 1 --config PREDICTOR 2 ' + path\n",
    "        if run:\n",
    "            result = subprocess.check_output(pyr_cmd)\n",
    "    \n",
    "    return stats_cmd, pyr_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28e9f1-709e-42e2-8dd0-375538b27fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pyramids and stats for the images with concurrent threads\n",
    "dem_dir = r\"C:\\scratch\\ecofor\"\n",
    "tile_sets = ['chm_025m'] #['dsm_1m', 'dtm_1m'] #'chm_1m'] #\n",
    "\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "for tile_set in tile_sets:\n",
    "    tile_dir = os.path.join(dem_dir, tile_set)\n",
    "    paths = glob(os.path.join(tile_dir, \"*.tif\"))\n",
    "    for path in paths:\n",
    "        stat_cmd, pyr_cmd = pyr_stats(path, nodata=None, run=False)\n",
    "        if not os.path.exists(path+\".aux.xml\"):\n",
    "            stat_cmds.append(stat_cmd)\n",
    "        if not os.path.exists(path+\".ovr\"):\n",
    "            pyr_cmds.append(pyr_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94184c6f-4816-421f-9b0f-66feaa649085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f17a4-2beb-4101-b649-22122482ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if tile stats are really necessary but approx stats are fast\n",
    "cmd_concurrent(stat_cmds, threads=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fa63f-bd9f-403a-8ae7-f882285e2c93",
   "metadata": {},
   "source": [
    "### Mosaics\n",
    "Generate virtual mosaics of DEMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65921968-20a6-41a3-9168-c9272f6725f8",
   "metadata": {},
   "source": [
    "**VRTs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cc146-9a9e-4976-beb5-becee16372e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = r\"C:\\scratch\\ecofor\"\n",
    "tile_sets = ['chm_025m'] #['dsm_1m', 'dtm_1m'] #'chm_1m'] #\n",
    "\n",
    "# template_path = r\"J:\\projects\\ECOFOR\\boundaries\\greaterkruger_utm36n.tif\"\n",
    "# with rasterio.open(template_path) as src:\n",
    "#     te = \" \".join([str(b) for b in src.bounds])\n",
    "\n",
    "for tile_set in tile_sets:\n",
    "    indir = os.path.join(basedir, tile_set)\n",
    "    vrt_dir = basedir   \n",
    "    outname = tile_set+\".vrt\"\n",
    "\n",
    "    # don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(vrt_dir)\n",
    "    \n",
    "    paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "    paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "    paths.sort()\n",
    "    \n",
    "    cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "    # cmd = \"gdalbuildvrt -te \" + te + \" \" + outname + \" \" + \" \".join(paths) # template extent\n",
    "    stdout = subprocess.check_output(cmd)\n",
    "    \n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce067ea-5761-4325-b65b-72518b627d87",
   "metadata": {},
   "source": [
    "**Tile-based pyramids and stats**  \n",
    "Creating the VRT after generating pyramids for tiles will automatically have the VRT use the tile pyramids, but calculating stats wipes this out so the line indicating there are virtual overviews needs to be added back again using gdaladdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8c182-4582-49cb-ad9d-160dea0e78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = r\"C:\\scratch\\ecofor\"\n",
    "tile_sets = ['chm_025m'] #['dsm_1m', 'dtm_1m'] #'chm_1m'] #\n",
    "paths = [os.path.join(basedir, i+'.vrt') for i in tile_sets]\n",
    "    \n",
    "stat_cmds = []\n",
    "pyr_cmds = []\n",
    "for path in paths:\n",
    "    stat_cmds.append('C:\\\\OSGeo4W64\\\\bin\\\\gdalinfo.exe -approx_stats ' + path) # for some reason the python environment version isn't working so use OSGeo\n",
    "    cmd_concurrent(stat_cmds, threads=3)\n",
    "\n",
    "    pyr_cmds.append('gdaladdo --config VRT_VIRTUAL_OVERVIEWS YES ' + path) # 2 4 8 16 32\n",
    "    cmd_concurrent(pyr_cmds, threads=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837ba29-f964-4714-bbba-d2132c3c1d2f",
   "metadata": {},
   "source": [
    "# Aerial orthomosaics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf3873-5df5-4df5-8283-bed307f48c45",
   "metadata": {},
   "source": [
    "**Make pyramids and stats**\n",
    "\n",
    "TODO: give proper extent for vrt. then use vrt to retile the imagery and apply compression and other good tiff settings. Maybe compress with jpeg and photometric for much smaller file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c5451-9852-4ecb-b2a8-8072165e6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pyramids and stats for the images with concurrent threads\n",
    "tile_dir = r\"H:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018\"\n",
    "paths = glob(os.path.join(tile_dir, \"*.tif\"))\n",
    "\n",
    "stat_cmds, pyr_cmds = [], []\n",
    "for path in paths:\n",
    "    stat_cmd, pyr_cmd = pyr_stats(path, nodata=None, run=False)\n",
    "    if not os.path.exists(path+\".aux.xml\"):\n",
    "        stat_cmds.append(stat_cmd)\n",
    "    if not os.path.exists(path+\".ovr\"):\n",
    "        pyr_cmds.append(pyr_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe8281-c221-47df-ba5d-e1eec9ce8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(pyr_cmds, threads=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e48fd0-660b-416c-af2f-1410142c1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_concurrent(stat_cmds, threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84c862-7e50-4283-af2d-c16fc8bf50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRT\n",
    "indir = r\"F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018\"\n",
    "vrt_dir = r\"F:\\ECOFOR\\aerial_imagery\"  \n",
    "outname = \"KNP_ortho025m_2018.vrt\"\n",
    "\n",
    "# don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "cwd = os.getcwd()\n",
    "os.chdir(vrt_dir)\n",
    "\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "paths.sort()\n",
    "\n",
    "cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "# cmd = \"gdalbuildvrt -te \" + te + \" \" + outname + \" \" + \" \".join(paths) # template extent\n",
    "stdout = subprocess.check_output(cmd)\n",
    "\n",
    "os.chdir(cwd)\n",
    "\n",
    "# # Use tile-based pyramids and stats\n",
    "# path = os.path.join(vrt_dir, outname)    \n",
    "\n",
    "# cmd = 'C:\\\\OSGeo4W64\\\\bin\\\\gdalinfo.exe -approx_stats ' + path # for some reason the python environment version isn't working so use OSGeo\n",
    "# stdout = subprocess.check_output(cmd)\n",
    "\n",
    "# cmd = 'gdaladdo --config VRT_VIRTUAL_OVERVIEWS YES ' + path # 2 4 8 16 32\n",
    "# stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc913c58-0f86-4d21-94a0-b1ddbba35264",
   "metadata": {},
   "source": [
    "**Retile as JPEG compressed and mosaic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d82b7c-71d4-440b-b5e6-2226abf8b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origvrt_path = r\"F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018.vrt\"\n",
    "\n",
    "# with rasterio.open(origvrt_path) as src:\n",
    "#     bbox = src.bounds\n",
    "\n",
    "# left = np.floor(bbox.left / 10) * 10\n",
    "# bottom = np.floor(bbox.bottom / 10) * 10\n",
    "# right = np.ceil(bbox.right / 10) * 10\n",
    "# top = np.ceil(bbox.top / 10) * 10\n",
    "\n",
    "# te = \" \".join([str(i) for i in [left, bottom, right, top]])\n",
    "# print(bbox)\n",
    "# print(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e77bf2-0865-4ae8-b296-af7f27f0c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target extent\n",
    "indir = r\"F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018\"\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "\n",
    "bounds = []\n",
    "for path in paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        bounds.append(shapely.geometry.box(*src.bounds))\n",
    "\n",
    "bbox = gpd.GeoSeries(bounds).unary_union.bounds\n",
    "left = np.floor(bbox[0] / 10) * 10\n",
    "bottom = np.floor(bbox[1] / 10) * 10\n",
    "right = np.ceil(bbox[2] / 10) * 10\n",
    "top = np.ceil(bbox[3] / 10) * 10\n",
    "\n",
    "te = \" \".join([str(i) for i in [left, bottom, right, top]])\n",
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc314ce-8746-42c3-9669-5a75a850d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRT\n",
    "indir = r\"F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018\"\n",
    "vrt_dir = r\"F:\\ECOFOR\\aerial_imagery\"  \n",
    "outname = \"KNP_ortho025m_2018.vrt\"\n",
    "\n",
    "# don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "cwd = os.getcwd()\n",
    "os.chdir(vrt_dir)\n",
    "\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "paths.sort()\n",
    "\n",
    "# cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "cmd = \"gdalbuildvrt -te \" + te + \" -tr 0.25 0.25 -srcnodata 0 \" + outname + \" \" + \" \".join(paths) # template extent\n",
    "stdout = subprocess.check_output(cmd)\n",
    "\n",
    "os.chdir(cwd)\n",
    "\n",
    "# # Use tile-based pyramids and stats\n",
    "# path = os.path.join(vrt_dir, outname)    \n",
    "\n",
    "# cmd = 'C:\\\\OSGeo4W64\\\\bin\\\\gdalinfo.exe -approx_stats ' + path # for some reason the python environment version isn't working so use OSGeo\n",
    "# stdout = subprocess.check_output(cmd)\n",
    "\n",
    "# cmd = 'gdaladdo --config VRT_VIRTUAL_OVERVIEWS YES ' + path # 2 4 8 16 32\n",
    "# stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec51aa-df9a-451e-abac-42ab8fc935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try translate of a tile\n",
    "vrt_path = r\"F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018.vrt\"\n",
    "outpath = r\"C:\\scratch\\ecofor\\ortho\\KNP_ortho025m_2018_tile00h00v.tif\"\n",
    "cmd = \"gdal_translate -srcwin 0 0 50000 50000 -a_nodata 0 -co COMPRESS=JPEG -co JPEG_QUALITY=75 -co PHOTOMETRIC=YCBCR -co TILED=YES -co BIGTIFF=YES -co NUM_THREADS=ALL_CPUS \" + vrt_path + \" \" + outpath\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71280c1f-3ebb-4a81-a351-d3894e5a08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(r\"C:\\scratch\\ecofor\\ortho\\KNP_ortho025m_2018_tile00h00v.tif\") as src:\n",
    "    print(src.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f966cd6-27d5-4098-90c6-7b86b0046531",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# try with rasterio read and then write\n",
    "window = rasterio.windows.Window(200000,200000, 50000, 50000)  \n",
    "with rasterio.open(r\"F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018.vrt\") as src:\n",
    "    print(src.profile)\n",
    "    arr = src.read(window=window)\n",
    "    # w, h = src.width, src.height\n",
    "\n",
    "kwargs = src.meta.copy()\n",
    "kwargs.update({\n",
    "    'height': window.height,\n",
    "    'width': window.width,\n",
    "    'transform': rasterio.windows.transform(window, src.transform)})\n",
    "\n",
    "kwargs['compress'] = 'jpeg'\n",
    "kwargs['tiled'] = 'yes'\n",
    "kwargs['photometric'] = 'ycbcr'\n",
    "kwargs['JPEG_QUALITY'] = '75'\n",
    "kwargs['BIGTIFF'] = 'gest'\n",
    "kwargs['NUM_THREADS'] = 'ALL_CPUS'\n",
    "kwargs['driver'] = 'GTiff'\n",
    "\n",
    "outpath = r\"C:\\scratch\\ecofor\\ortho\\KNP_ortho025m_2018_tile04h04v_rio.tif\"\n",
    "with rasterio.open(outpath, 'w', **kwargs) as dst:\n",
    "    dst.write(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd208c1-b4de-4dcb-9689-95360352d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cmd = r\"gdal_translate -srcwin 200000 200000 50000 50000 -a_nodata 0 -co COMPRESS=JPEG -co JPEG_QUALITY=75 -co PHOTOMETRIC=YCBCR -co TILED=YES -co BIGTIFF=YES F:\\ECOFOR\\aerial_imagery\\KNP_ortho025m_2018.vrt C:\\scratch\\ecofor\\ortho\\KNP_ortho025m_2018_tile04h04v_t2.tif\"\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310ef4c-788a-493a-91c1-2977861f62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate gdal_translate commands to save tiles concurrently\n",
    "# F:\\ECOFOR\\aerial_imagery\n",
    "vrt_path = r\"C:\\scratch\\ecofor\\ortho\\KNP_ortho025m_2018.vrt\"\n",
    "with rasterio.open(vrt_path) as src: \n",
    "    rows = src.height//50000\n",
    "    cols = src.width//50000\n",
    "\n",
    "# rows = 22\n",
    "cmds = []\n",
    "for h in range(0,cols+1):\n",
    "    for v in range(0,rows+1):\n",
    "        outpath = r\"C:\\scratch\\ecofor\\ortho\\compress_tiles\\KNP_ortho025m_2018_h{:02d}v{:02d}.tif\".format(h, v)\n",
    "        if os.path.exists(outpath):\n",
    "            continue\n",
    "        cmd = r\"gdal_translate -srcwin \" + str(h*50000) + \" \" + str(v*50000) + r\" 50000 50000 -a_nodata 0 -co COMPRESS=JPEG -co JPEG_QUALITY=75 -co PHOTOMETRIC=YCBCR -co TILED=YES -co BIGTIFF=YES \" + vrt_path + \" \" + outpath\n",
    "        cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f34b9-fe60-42b8-a088-1dc70283c3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a116da8-8742-4d98-8e79-85fe41cd1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cmd_concurrent(cmds, threads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf835f7-731c-4a5b-8df0-30ff420d58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRT\n",
    "indir = r\"C:\\scratch\\ecofor\\ortho\\compress_tiles\"\n",
    "vrt_dir = r\"C:\\scratch\\ecofor\\ortho\"  \n",
    "outname = \"KNP_ortho025m_2018_compressed.vrt\"\n",
    "\n",
    "# don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "cwd = os.getcwd()\n",
    "os.chdir(vrt_dir)\n",
    "\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "paths = [os.path.relpath(p, vrt_dir) for p in paths]\n",
    "paths.sort()\n",
    "\n",
    "cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)  # no template\n",
    "# cmd = \"gdalbuildvrt -te \" + te + \" \" + outname + \" \" + \" \".join(paths) # template extent\n",
    "stdout = subprocess.check_output(cmd)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29439509-1586-4c8b-ab6b-ea81e425d8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use tile-based pyramids and stats\n",
    "path = os.path.join(vrt_dir, outname)    \n",
    "\n",
    "cmd = 'C:\\\\OSGeo4W64\\\\bin\\\\gdalinfo.exe -approx_stats ' + path # for some reason the python environment version isn't working so use OSGeo\n",
    "stdout = subprocess.check_output(cmd)\n",
    "\n",
    "cmd = 'gdaladdo --config VRT_VIRTUAL_OVERVIEWS YES ' + path # 2 4 8 16 32\n",
    "stdout = subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ceb68-37f2-4d77-b69c-7bcf46d12fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "paths = glob(r\"C:\\scratch\\ecofor\\ortho\\compress_tiles\\*.tif\")\n",
    "for path in paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        prof = src.profile\n",
    "        try:\n",
    "            src.statistics(1, approx=True)\n",
    "        except:\n",
    "            empty.append(path)\n",
    "len(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776327a2-0a87-448c-93c3-07eb6a6b1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to instead export tiles one at a time with gdalwarp instead of vrt to translate. Warp can be faster sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2304a4-016a-4fac-8ae7-46209ce0df95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84ad99be-97c3-4a5c-8aac-1df21e20b824",
   "metadata": {},
   "source": [
    "# Extract Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea6abc-7f80-4c86-9f6f-636a4a49a7a8",
   "metadata": {},
   "source": [
    "## Filter and sample GEDI footprints\n",
    "Save footprints with subset of columns and unix timestamps for extraction of CCDC in GEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ad9d8-38f9-44f4-9c05-9e2e95e9b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\scratch\\ECOFOR\\gedi\\GEDI_2AB_2019to2023.parquet\"\n",
    "outpath = r\"H:\\ECOFOR\\gedi\\gedi_data\\04_gedi_filtered_data_shp\\GEDI_2AB_2019to2023_leafon_sampy500m.parquet\"\n",
    "df = gpd.read_parquet(path)\n",
    "\n",
    "# Filter to MGRS tiles\n",
    "df = df.to_crs(epsg=32636)\n",
    "tiles_path = r\"J:\\projects\\ECOFOR\\boundaries\\mgrs_utm36n.gpkg\"\n",
    "aoi = gpd.read_file(tiles_path)\n",
    "aoi = aoi.unary_union\n",
    "df = df[df.intersects(aoi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c9a9e-8d4e-442b-9628-d232eb993e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_time'] = pd.to_datetime(df['delta_time'])\n",
    "df['millis'] = df['delta_time'].astype(np.int64) // 10**6\n",
    "\n",
    "# Filter to points that will be used in modeling\n",
    "df = df[df['rh98']<45] # Remove unreasonable points\n",
    "df = df[(df['delta_time'].dt.day_of_year < 121) | (df['delta_time'].dt.day_of_year > 305)] # keep only leaf-on (Nov - Apr) as defined in Li 2023\n",
    "\n",
    "# Sample one point in every 500 m x 500 m grid per rain year\n",
    "# Rain year is defined as the year beginning with the start of the dry season (121-273) and the following wet season (274-120)\n",
    "# e.g., rain year 2018 is May 1, 2018 - April 30 2019\n",
    "df['year'] = df['delta_time'].dt.year\n",
    "df['rain_year'] = df['year'].copy()\n",
    "df.loc[df['delta_time'].dt.day_of_year < 121, 'rain_year'] += -1 \n",
    "\n",
    "df['x'], df['y'] = df['geometry'].x, df['geometry'].y\n",
    "df['x_grid'], df['y_grid'] = ((df['x']//500) * 500).astype(int), ((df['y']//500) * 500).astype(int)\n",
    "\n",
    "dfsampy = df.groupby(['rain_year', 'x_grid', 'y_grid']).sample(1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd491e-b15f-41c4-9b63-0637188ab232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "dfsampy.to_parquet(outpath)\n",
    "\n",
    "# Save to geopackage for visualization\n",
    "dfout = dfsampy.copy()\n",
    "dfout['delta_time'] = dfout['delta_time'].astype(str)\n",
    "cols = ['shot_number', 'lat_lowestmode', 'lon_lowestmode', 'delta_time', 'year', 'rain_year', 'x', 'y', 'x_grid', 'y_grid', 'geometry']\n",
    "dfout[cols].to_file(os.path.splitext(outpath)[0]+\"_metacols.gpkg\", driver=\"GPKG\")\n",
    "\n",
    "# Save to shapefile with base columns for use in GEE sampling\n",
    "dfout['shot_num'] = dfout['shot_number']\n",
    "cols = ['shot_num', 'delta_time', 'year', 'rain_year', 'millis', 'geometry']\n",
    "dfout[cols].to_file(os.path.splitext(outpath)[0]+\"_shotdate.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb8e71-9cd3-4c3e-8ab9-62493cae26b9",
   "metadata": {},
   "source": [
    "## CCDC - get synthetic values  \n",
    "Calculate synthentic image values at given dates using the coefficients for the extracted segment.\n",
    "Note that if the date used falls outside the segment then the value could be very far from the real/expected value at that date. This synthetic value could still be useful for representing the expected reflectance during a certain time of year given the segment coefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b087c-8e1b-4699-b184-2812cc840907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GEE output into a single dataframe with synthetic values at dry/wet dates added\n",
    "paths = glob(r\"H:\\ECOFOR\\gedi\\extracted\\ccdc_l30s2_gee\\*.csv\") # - repeate for l30 and l30s2\n",
    "outpath = r\"H:\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_l30s2_ccdc.csv\" \n",
    "\n",
    "cdf = pd.concat([pd.read_csv(p) for p in paths], axis=0)\n",
    "cdf = cdf.rename(columns={'shot_num':'shot_number'})\n",
    "cdf = cdf.drop(columns = ['system:index', '.geo'])\n",
    "\n",
    "# # Check for missing rows \n",
    "# # L30 has some because of pixels with nodata\n",
    "# odf = gpd.read_parquet(r\"H:\\ECOFOR\\gedi\\gedi_data\\04_gedi_filtered_data_shp\\GEDI_2AB_2019to2023_leafon_sampy500m.parquet\")\n",
    "# df['shot_number'] = df['shot_number'].astype(str)\n",
    "# mdf = pd.merge(odf[['shot_number', 'geometry', 'lat_lowestmode', 'lon_lowestmode']], df[['shot_number', 'delta_time', 'millis']], how='outer', on='shot_number', indicator=True)\n",
    "# mdf = gpd.GeoDataFrame(mdf, geometry=gpd.points_from_xy(mdf['lon_lowestmode'], mdf['lat_lowestmode']), crs='EPSG:4326')\n",
    "# sub = mdf[mdf['_merge']=='left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ceab32-39f3-426b-9e34-87ef35ecf629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CCDC extraction\n",
    "# ccdc_path = r\"H:\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_l30s2_ccdc.csv\" #r\"H:\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_l30s2_ccdc.csv\"\n",
    "# cdf = pd.read_csv(ccdc_path)\n",
    "# cdf = cdf.drop(columns=['system:index', '.geo', 'millis', 'delta_time', 'shot_num'])\n",
    "\n",
    "bands = cdf.columns[cdf.columns.str.endswith('_INTP')].str.split('_').str[0].tolist()\n",
    "\n",
    "# normalize intercepts to date at middle of segment\n",
    "# The normalized intercepts may be a better representation of average reflectance\n",
    "for band in bands:\n",
    "    cdf['mid_time'] = (cdf['tStart']+cdf['tEnd'])/2. # middle of the segment\n",
    "    cdf[band+'_INTPnorm'] = cdf[band+'_INTP']+ cdf[band+'_SLP'] * cdf['mid_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01faca72-1003-43bf-8856-1794800c5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dates to get synthetic values\n",
    "# TODO: Think more carefully about dates or test all days of year with a test dataset. Look at correlation or relationship between sythetic band values and the gedi metrics.\n",
    "cdf['millis_wet'] = cdf['rain_year'].apply(lambda y: pd.Timestamp(year=y, month=2, day=1).timestamp()*1000)\n",
    "cdf['millis_dry'] = cdf['rain_year'].apply(lambda y: pd.Timestamp(year=y, month=9, day=15).timestamp()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e26fdf-94eb-4a16-a5c1-b8bc93e9ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sythetic values for a date band\n",
    "date_bands = ['millis_dry', 'millis_wet']\n",
    "\n",
    "for date_band in date_bands:\n",
    "    dsuffix = date_band.split('_')[1]\n",
    "    date_fmt=2 # millis\n",
    "\n",
    "    pi2 = 2 * np.pi\n",
    "    omegas = {0:pi2 / 365.25,\n",
    "              1:pi2,\n",
    "              2:pi2 / (1000 * 60 * 60 * 24 * 365.25)}\n",
    "    omega = omegas[date_fmt]\n",
    "    coef_list = [\"INTP\", \"SLP\", \"COS\", \"SIN\", \"COS2\", \"SIN2\", \"COS3\", \"SIN3\"]\n",
    "\n",
    "    def make_tseries(date):\n",
    "        tseries = pd.Series([1., float(date),\n",
    "                             np.cos(date*omega), np.sin(date*omega),\n",
    "                             np.cos(date*omega*2), np.sin(date*omega*2), \n",
    "                             np.cos(date*omega*3), np.sin(date*omega*3)],\n",
    "                           index=coef_list)\n",
    "        return tseries\n",
    "\n",
    "    tdf = cdf[date_band].apply(make_tseries)\n",
    "\n",
    "    for band in bands:\n",
    "        bcols = [band+'_'+c for c in coef_list]\n",
    "        cdf[band+'_'+dsuffix] = (cdf[bcols] * tdf.values).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3302f-6bd4-4e81-9d15-cb7c46da5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.to_csv(outpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbff50-2103-4004-9952-72b767912358",
   "metadata": {},
   "source": [
    "## Land Cover\n",
    "Extract 2020 South Africa National Land Cover for use in analysis and possibly modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6902e3-d15b-4368-8e58-574a7ea9e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SA NLC 2020 values for the sampled GEDI shots\n",
    "path = r\"J:\\projects\\ECOFOR\\gedi\\gedi_data\\04_gedi_filtered_data_shp\\GEDI_2AB_2019to2023_leafon_sampy500m.parquet\"\n",
    "rast_path = r\"J:\\projects\\ECOFOR\\lcluc\\SANLC\\2020\\SA_NLC_2020_GEO.tif\"\n",
    "outpath = r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_sanlc20.csv\"\n",
    "\n",
    "df = pd.read_parquet(path, columns=['shot_number', 'lat_lowestmode', 'lon_lowestmode'])\n",
    "df[\"shot_number\"] = df[\"shot_number\"].astype(np.int64)\n",
    "df = df.set_index(\"shot_number\")\n",
    "\n",
    "with rasterio.open(rast_path) as src:\n",
    "    transform = src.transform\n",
    "    arr = src.read(1)\n",
    "\n",
    "df['row'], df['col'] = rasterio.transform.rowcol(transform, df['lon_lowestmode'], df['lat_lowestmode'])\n",
    "df['sanlc20_val'] = df.apply(lambda r: arr[int(r['row']), int(r['col'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ccb2f-1582-4a0f-a18d-3dd4a11b58c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap value to different 2020 classification schemes\n",
    "rat = gpd.read_file(rast_path+'.vat.dbf').drop('geometry', axis=1)\n",
    "class_dict = rat.set_index('Value')['Class_Name'].to_dict()\n",
    "salcc1_dict = rat.set_index('Value')['SALCC_1'].to_dict()\n",
    "salcc2_dict = rat.set_index('Value')['SALCC_2'].to_dict()\n",
    "\n",
    "df['sanlc20_name'] = df['sanlc20_val'].map(class_dict)\n",
    "df['sanlc20_salcc1'] = df['sanlc20_val'].map(salcc1_dict)\n",
    "df['sanlc20_salcc2'] = df['sanlc20_val'].map(salcc2_dict)\n",
    "\n",
    "# Also remap to C20 classification scheme used for SA NLC change assessment\n",
    "reclass_path = r\"J:\\projects\\ECOFOR\\lcluc\\SANLC\\2020\\SA_NLC_2020 _Accuracy_Assessment_Report\\acc_class_remap.csv\"\n",
    "reclass = pd.read_csv(reclass_path)\n",
    "\n",
    "c20_dict = reclass.set_index('orig_class')['c20_name'].to_dict()\n",
    "df['sanlc20_c20'] = df['sanlc20_val'].map(c20_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d415cf-0cd3-43c4-8f79-d765d2585066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "sanlc_cols = ['sanlc20_val', 'sanlc20_name', 'sanlc20_salcc2', 'sanlc20_salcc1', 'sanlc20_c20']\n",
    "df[sanlc_cols].to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912fbfd-d38c-438c-ba3b-c0fbe611a86d",
   "metadata": {},
   "source": [
    "## Merge predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257ae56-2a85-4bde-ad64-4ce55f68b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict = {\n",
    "    \"gedi\": r\"J:\\projects\\ECOFOR\\gedi\\gedi_data\\04_gedi_filtered_data_shp\\GEDI_2AB_2019to2023_leafon_sampy500m.parquet\",\n",
    "    \"l30\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_l30_ccdc.csv\",\n",
    "    \"hls\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_l30s2_ccdc.csv\",\n",
    "    \"lt\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_lt.csv\",\n",
    "    \"ps\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_planetscope.csv\",\n",
    "    \"palsar\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_palsar.csv\",\n",
    "    \"climate\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_climate.csv\",\n",
    "    \"soil\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_soil.csv\",\n",
    "    \"topo\": r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_topo.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for src, path in source_dict.items():\n",
    "    if src=='gedi':\n",
    "        df = gpd.read_parquet(path)\n",
    "        df[\"shot_number\"] = df[\"shot_number\"].astype(np.int64)\n",
    "        df = df.set_index(\"shot_number\")\n",
    "        dfs.append(df)\n",
    "    else: \n",
    "        df = pd.read_csv(path).set_index(\"shot_number\")\n",
    "        df = df.add_prefix(src+'_')\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=1)\n",
    "df.set_geometry('geometry', inplace=True, crs=32636)\n",
    "\n",
    "# Save as parquet with flat column index\n",
    "# (Saving geodataframe to parquet with hierarchical columns not working, but would work with pandas with geometry call as WKT)\n",
    "df.to_parquet(r\"J:\\projects\\ECOFOR\\gedi\\extracted\\GEDI_2AB_2019to2023_leafon_sampy500m_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d950b-b34e-4aba-ac1e-1f287801cded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ecofor]",
   "language": "python",
   "name": "conda-env-ecofor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
